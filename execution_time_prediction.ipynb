{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "cd274492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_execution_time_predictor.train_utils import (\n",
    "    build_stage_features,\n",
    "    train_linear_predictor,\n",
    "    train_tree_predictor,\n",
    ")\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf6cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List your files here\n",
    "# files = [\n",
    "#     \"arxiv_summarization_rps_3.jsonl\",\n",
    "#     \"decode_decode_profiling_tp0.jsonl\",\n",
    "#     \"prefill_prefill_profiling_tp0.jsonl\",\n",
    "#     \"prefill_profiling_chunked_cache_prefix_caching_prefill_cache_profiling_tp0.jsonl\",\n",
    "#     \"prefill_with_prefix_caching_prefill_cache_profiling_tp0.jsonl\",\n",
    "#     \"splitwise_code_rps_5.jsonl\",\n",
    "#     \"splitwise_code_rps_10.jsonl\"\n",
    "# ]\n",
    "# model_name = \"Qwen_Qwen3_4B_TP_1\"\n",
    "# model_name = \"Qwen_Qwen3_8B_TP_1\"\n",
    "model_name = \"deepseek_ai_DeepSeek_R1_Distill_Qwen_1.5B_TP_1\"\n",
    "folder = \"profile_output_a100\"\n",
    "files = os.listdir(\"profile_output_a100/\" + model_name)\n",
    "files_folder = [os.path.join(\"profile_output_a100/\" + model_name, f) for f in files]\n",
    "dfs = [pd.read_json(f, lines=True) for f in files_folder]\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "decode_mask = (combined_df[\"forward_mode\"] == \"decode\") & (combined_df[\"skew\"] == 0.0)\n",
    "grouped_df = combined_df[decode_mask]\n",
    "group_keys = [\"batch_size\", \"total_token_length\"]\n",
    "agg_dict = {\n",
    "    col: \"mean\" if col in [\"latency\", \"throughput\"] else \"first\"\n",
    "    for col in grouped_df.columns\n",
    "    if col not in group_keys\n",
    "}\n",
    "decode_grouped = grouped_df.groupby(group_keys).agg(agg_dict).reset_index()\n",
    "\n",
    "combined_df = pd.concat([combined_df[~decode_mask], decode_grouped], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8867f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3900407/748055771.py:11: UserWarning:\n",
      "\n",
      "Boolean Series key will be reindexed to match DataFrame index.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prefill_mask = (combined_df[\"forward_mode\"] == \"prefill\") & (combined_df[\"skew\"] == 0.0)\n",
    "grouped_df = combined_df[prefill_mask]\n",
    "group_keys = [\"batch_size\", \"total_token_length\"]\n",
    "agg_dict = {\n",
    "    col: \"mean\" if col in [\"latency\", \"throughput\"] else \"first\"\n",
    "    for col in grouped_df.columns\n",
    "    if col not in group_keys\n",
    "}\n",
    "prefill_grouped = grouped_df.groupby(group_keys).agg(agg_dict).reset_index()\n",
    "combined_df = pd.concat(\n",
    "    [combined_df[~prefill_mask], prefill_grouped], ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7060efaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>total_token_length</th>\n",
       "      <th>skew</th>\n",
       "      <th>combined_seq_lens</th>\n",
       "      <th>cached_prefix_lens</th>\n",
       "      <th>new_extend_lens</th>\n",
       "      <th>total_extend_len</th>\n",
       "      <th>latency</th>\n",
       "      <th>throughput</th>\n",
       "      <th>forward_mode</th>\n",
       "      <th>cache_percent</th>\n",
       "      <th>chunked</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>process_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>122.281230</td>\n",
       "      <td>prefill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007621</td>\n",
       "      <td>131.216543</td>\n",
       "      <td>prefill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007485</td>\n",
       "      <td>133.597917</td>\n",
       "      <td>prefill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>133.590155</td>\n",
       "      <td>prefill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.014628</td>\n",
       "      <td>136.720447</td>\n",
       "      <td>prefill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10703</th>\n",
       "      <td>256</td>\n",
       "      <td>6048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2...</td>\n",
       "      <td>6048.0</td>\n",
       "      <td>0.079694</td>\n",
       "      <td>75889.992021</td>\n",
       "      <td>prefill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10704</th>\n",
       "      <td>256</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 3...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 3...</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>0.104501</td>\n",
       "      <td>78391.540090</td>\n",
       "      <td>prefill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10705</th>\n",
       "      <td>256</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 4...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 4...</td>\n",
       "      <td>10240.0</td>\n",
       "      <td>0.128872</td>\n",
       "      <td>79458.672383</td>\n",
       "      <td>prefill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10706</th>\n",
       "      <td>256</td>\n",
       "      <td>13000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 5...</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>0.162167</td>\n",
       "      <td>80164.458964</td>\n",
       "      <td>prefill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10707</th>\n",
       "      <td>256</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 6...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 6...</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>0.204660</td>\n",
       "      <td>80054.651577</td>\n",
       "      <td>prefill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10708 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       batch_size  total_token_length  skew  \\\n",
       "0               1                   1   0.0   \n",
       "1               1                   1   0.5   \n",
       "2               1                   1   1.0   \n",
       "3               1                   1   1.5   \n",
       "4               1                   2   0.0   \n",
       "...           ...                 ...   ...   \n",
       "10703         256                6048   0.0   \n",
       "10704         256                8192   0.0   \n",
       "10705         256               10240   0.0   \n",
       "10706         256               13000   0.0   \n",
       "10707         256               16384   0.0   \n",
       "\n",
       "                                       combined_seq_lens  \\\n",
       "0                                                    [1]   \n",
       "1                                                    [1]   \n",
       "2                                                    [1]   \n",
       "3                                                    [1]   \n",
       "4                                                    [2]   \n",
       "...                                                  ...   \n",
       "10703  [24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2...   \n",
       "10704  [32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 3...   \n",
       "10705  [40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 4...   \n",
       "10706  [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 5...   \n",
       "10707  [64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 6...   \n",
       "\n",
       "                                      cached_prefix_lens  \\\n",
       "0                                                    [0]   \n",
       "1                                                    [0]   \n",
       "2                                                    [0]   \n",
       "3                                                    [0]   \n",
       "4                                                    [0]   \n",
       "...                                                  ...   \n",
       "10703  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10704  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10705  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10706  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10707  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                         new_extend_lens  total_extend_len  \\\n",
       "0                                                    [1]               1.0   \n",
       "1                                                    [1]               1.0   \n",
       "2                                                    [1]               1.0   \n",
       "3                                                    [1]               1.0   \n",
       "4                                                    [2]               2.0   \n",
       "...                                                  ...               ...   \n",
       "10703  [24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2...            6048.0   \n",
       "10704  [32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 3...            8192.0   \n",
       "10705  [40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 4...           10240.0   \n",
       "10706  [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 5...           13000.0   \n",
       "10707  [64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 6...           16384.0   \n",
       "\n",
       "        latency    throughput forward_mode  cache_percent chunked  timestamp  \\\n",
       "0      0.008178    122.281230      prefill            NaN     NaN        NaN   \n",
       "1      0.007621    131.216543      prefill            NaN     NaN        NaN   \n",
       "2      0.007485    133.597917      prefill            NaN     NaN        NaN   \n",
       "3      0.007486    133.590155      prefill            NaN     NaN        NaN   \n",
       "4      0.014628    136.720447      prefill            NaN     NaN        NaN   \n",
       "...         ...           ...          ...            ...     ...        ...   \n",
       "10703  0.079694  75889.992021      prefill            NaN    None        NaN   \n",
       "10704  0.104501  78391.540090      prefill            NaN    None        NaN   \n",
       "10705  0.128872  79458.672383      prefill            NaN    None        NaN   \n",
       "10706  0.162167  80164.458964      prefill            NaN    None        NaN   \n",
       "10707  0.204660  80054.651577      prefill            NaN    None        NaN   \n",
       "\n",
       "       process_id  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "...           ...  \n",
       "10703         NaN  \n",
       "10704         NaN  \n",
       "10705         NaN  \n",
       "10706         NaN  \n",
       "10707         NaN  \n",
       "\n",
       "[10708 rows x 14 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f12ee4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"combined_profile_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9bc13ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['batch_size', 'total_token_length', 'skew', 'combined_seq_lens',\n",
       "       'cached_prefix_lens', 'new_extend_lens', 'total_extend_len', 'latency',\n",
       "       'throughput', 'forward_mode', 'cache_percent', 'chunked', 'timestamp',\n",
       "       'process_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435f394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "29cd56e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df.to_csv(\"combined_profile_results.csv\", index=False)\n",
    "import numpy as np\n",
    "\n",
    "combined_df[\"total_extend_len\"] = combined_df[\"total_extend_len\"].fillna(\n",
    "    combined_df[\"new_extend_lens\"].apply(sum)\n",
    ")\n",
    "\n",
    "combined_df[\"input_len\"] = combined_df[\"combined_seq_lens\"].apply(\n",
    "    lambda x: np.mean(x) if isinstance(x, list) else 0\n",
    ")\n",
    "prefill_df = combined_df[combined_df[\"forward_mode\"] == \"prefill\"]\n",
    "decode_df = combined_df[combined_df[\"forward_mode\"] == \"decode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ed5f57a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _safe_list(x):\n",
    "    \"\"\"Guard against NaN or scalar entries that sneak in.\"\"\"\n",
    "    return x if isinstance(x, (list, tuple, np.ndarray)) else [x]\n",
    "\n",
    "\n",
    "def build_stage_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Feature-engineer latency predictors for *both* prefill & decode rows.\n",
    "    The function assumes the raw frame still contains list-columns:\n",
    "      - combined_seq_lens\n",
    "      - cached_prefix_lens\n",
    "      - new_extend_lens\n",
    "    and extra scalar columns such as batch_size, latency, skew, cache_percent.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # 1.  Sequence-length distribution stats\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    df[\"len_max\"] = df[\"combined_seq_lens\"].apply(lambda x: np.max(_safe_list(x)))\n",
    "    df[\"len_min\"] = df[\"combined_seq_lens\"].apply(lambda x: np.min(_safe_list(x)))\n",
    "    df[\"len_std\"] = df[\"combined_seq_lens\"].apply(lambda x: np.std(_safe_list(x)))\n",
    "    df[\"len_p90\"] = df[\"combined_seq_lens\"].apply(\n",
    "        lambda x: np.percentile(_safe_list(x), 90)\n",
    "    )\n",
    "    df[\"len_p95\"] = df[\"combined_seq_lens\"].apply(\n",
    "        lambda x: np.percentile(_safe_list(x), 95)\n",
    "    )\n",
    "\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # 2.  Cached-prefix stats\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    df[\"cached_sum\"] = df[\"cached_prefix_lens\"].apply(lambda x: np.sum(_safe_list(x)))\n",
    "    df[\"cached_max\"] = df[\"cached_prefix_lens\"].apply(lambda x: np.max(_safe_list(x)))\n",
    "    df[\"cached_ratio\"] = df[\"cached_sum\"] / df[\"total_token_length\"].clip(lower=1)\n",
    "\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # 3.  Extension-stats (per call)\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    df[\"extend_sum\"] = df[\"new_extend_lens\"].apply(lambda x: np.sum(_safe_list(x)))\n",
    "    df[\"extend_max\"] = df[\"new_extend_lens\"].apply(lambda x: np.max(_safe_list(x)))\n",
    "    df[\"extend_mean\"] = df[\"new_extend_lens\"].apply(lambda x: np.mean(_safe_list(x)))\n",
    "    df[\"extend_std\"] = df[\"new_extend_lens\"].apply(lambda x: np.std(_safe_list(x)))\n",
    "    df[\"extend_p90\"] = df[\"new_extend_lens\"].apply(\n",
    "        lambda x: np.percentile(_safe_list(x), 90)\n",
    "    )\n",
    "\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # 4.  Skew / imbalance and memory-pressure proxies\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    df[\"imbalance\"] = df[\"len_max\"] / df[\"len_min\"].replace(0, np.nan)\n",
    "    df[\"cache_percent\"] = df.get(\"cache_percent\", np.nan)  # may already exist\n",
    "\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # 5.  Stage flag\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    df[\"is_prefill\"] = (df[\"forward_mode\"] == \"prefill\").astype(int)\n",
    "\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # 6.  “Classic” cost proxies (now using len_max instead of avg)\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # ATTENTION-FLOPs proxy: O(batch * len_max²) for prefill, O(batch * len_max) for decode\n",
    "    df[\"prod_ext_ctx\"] = np.where(\n",
    "        df[\"is_prefill\"] == 1,\n",
    "        df[\"batch_size\"] * (df[\"len_max\"] ** 2),\n",
    "        df[\"batch_size\"] * df[\"len_max\"],\n",
    "    )\n",
    "\n",
    "    # Tokens newly processed this step\n",
    "    df[\"num_new_tokens\"] = np.where(\n",
    "        df[\"is_prefill\"] == 1,\n",
    "        df[\"extend_sum\"],  # sum of prompt tokens\n",
    "        df[\"batch_size\"],  # one per sequence in decode\n",
    "    )\n",
    "\n",
    "    # Total context tokens “live” during this step\n",
    "    df[\"num_context_tokens\"] = df[\"batch_size\"] * df[\"len_max\"]\n",
    "\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # 7.  Target\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    df[\"time\"] = df[\"latency\"]\n",
    "\n",
    "    # ------- EXTRA SEQ / EXTENSION STATS -------\n",
    "    df[\"len_mean\"] = df[\"combined_seq_lens\"].apply(lambda x: np.mean(_lst(x)))\n",
    "    df[\"len_median\"] = df[\"combined_seq_lens\"].apply(lambda x: np.median(_lst(x)))\n",
    "    df[\"len_range\"] = df[\"len_max\"] - df[\"len_min\"]\n",
    "    df[\"len_p99\"] = df[\"combined_seq_lens\"].apply(lambda x: np.percentile(_lst(x), 99))\n",
    "    df[\"len_cv\"] = df[\"len_std\"] / df[\"len_mean\"].clip(lower=1)\n",
    "\n",
    "    df[\"extend_min\"] = df[\"new_extend_lens\"].apply(lambda x: np.min(_lst(x)))\n",
    "    df[\"extend_median\"] = df[\"new_extend_lens\"].apply(lambda x: np.median(_lst(x)))\n",
    "    df[\"extend_p99\"] = df[\"new_extend_lens\"].apply(lambda x: np.percentile(_lst(x), 99))\n",
    "    df[\"extend_cv\"] = df[\"extend_std\"] / df[\"extend_mean\"].clip(lower=1)\n",
    "\n",
    "    # ------- RATIOS & INTERACTIONS -------\n",
    "    df[\"prompt_ratio\"] = df[\"extend_sum\"] / df[\"total_token_length\"].clip(lower=1)\n",
    "    df[\"cached_peak_ratio\"] = df[\"cached_max\"] / df[\"len_max\"].clip(lower=1)\n",
    "    df[\"B_len_mean\"] = df[\"batch_size\"] * df[\"len_mean\"]\n",
    "    df[\"B_len_max_sq\"] = df[\"batch_size\"] * (df[\"len_max\"] ** 2)\n",
    "    df[\"cache_len_prod\"] = df[\"cache_percent\"] * df[\"len_max\"]\n",
    "\n",
    "    # ------- LOG-SPACE -------\n",
    "    for col in [\"len_max\", \"prod_ext_ctx\", \"num_context_tokens\"]:\n",
    "        df[f\"log_{col}\"] = np.log1p(df[col])\n",
    "\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # 8.  Select final columns\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    feature_cols = [\n",
    "        # token & attention proxies\n",
    "        \"num_new_tokens\",\n",
    "        \"prod_ext_ctx\",\n",
    "        \"num_context_tokens\",\n",
    "        # sequence-distribution\n",
    "        \"len_max\",\n",
    "        \"len_min\",\n",
    "        \"len_std\",\n",
    "        \"len_p90\",\n",
    "        \"len_p95\",\n",
    "        # cache stats\n",
    "        \"cached_sum\",\n",
    "        \"cached_max\",\n",
    "        \"cached_ratio\",\n",
    "        # extension stats\n",
    "        \"extend_max\",\n",
    "        \"extend_mean\",\n",
    "        \"extend_std\",\n",
    "        \"extend_p90\",\n",
    "        # imbalance / batch\n",
    "        \"batch_size\",\n",
    "        \"imbalance\",\n",
    "        # memory pressure\n",
    "        \"cache_percent\",\n",
    "        # stage\n",
    "        \"is_prefill\",\n",
    "        # sequence shape\n",
    "        \"len_mean\",\n",
    "        \"len_median\",\n",
    "        \"len_range\",\n",
    "        \"len_p99\",\n",
    "        \"len_cv\",\n",
    "        # extension shape\n",
    "        \"extend_min\",\n",
    "        \"extend_median\",\n",
    "        \"extend_p99\",\n",
    "        \"extend_cv\",\n",
    "        # ratios & interactions\n",
    "        \"prompt_ratio\",\n",
    "        \"cached_peak_ratio\",\n",
    "        \"B_len_mean\",\n",
    "        \"B_len_max_sq\",\n",
    "        \"cache_len_prod\",\n",
    "        # log space\n",
    "        \"log_len_max\",\n",
    "        \"log_prod_ext_ctx\",\n",
    "        \"log_num_context_tokens\",\n",
    "    ]\n",
    "\n",
    "    # Keep any hardware-specific knobs if present (they’re cheap to one-hot later)\n",
    "    #    hw_cols = [c for c in (\"gpu_name\", \"num_gpu\", \"dtype\", \"flash_attn_flag\") if c in df]\n",
    "    return df[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e638d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import List, cast\n",
    "\n",
    "\n",
    "def preprocess_input_for_prediction(\n",
    "    batch_size, avg_context_len, gpu, mode=\"prefill\"\n",
    ") -> List[float]:\n",
    "    if mode == \"prefill\":\n",
    "        num_new_tokens = batch_size * avg_context_len\n",
    "        prod_ext_ctx = batch_size * (avg_context_len**2)\n",
    "        num_context_tokens = avg_context_len * batch_size\n",
    "        num_batch_size = batch_size\n",
    "    else:\n",
    "        num_new_tokens = batch_size\n",
    "        prod_ext_ctx = batch_size * avg_context_len\n",
    "        num_context_tokens = avg_context_len * batch_size\n",
    "        num_batch_size = batch_size\n",
    "    return [num_new_tokens, prod_ext_ctx, num_context_tokens, num_batch_size]\n",
    "\n",
    "\n",
    "def build_stage_features(df: pd.DataFrame, stage: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build input features for latency modeling based on the inference stage.\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A dataframe with engineered features:\n",
    "        - num_new_tokens: total tokens processed/generated (models token compute)\n",
    "        - prod_ext_ctx: proxy for attention cost (quadratic or linear depending on stage)\n",
    "        - num_context_tokens: total context tokens active (models memory + cache pressure)\n",
    "        - batch_size: degree of parallelism\n",
    "        - time: latency target to be predicted\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # TOOD: Currently I just use the average input length, but I should take in the actual batch composition seq lens,\n",
    "    if stage == \"prefill\":\n",
    "        df[\"num_new_tokens\"] = df[\"batch_size\"] * df[\"input_len\"]\n",
    "        df[\"prod_ext_ctx\"] = df[\"batch_size\"] * (df[\"input_len\"] ** 2)\n",
    "        df[\"num_context_tokens\"] = df[\"batch_size\"] * df[\"input_len\"]\n",
    "        df[\"time\"] = df[\"latency\"]\n",
    "\n",
    "    elif stage == \"decode\":\n",
    "        # One token is generated per request per step\n",
    "        # Each new token attends to all previous context (linear in output_len)\n",
    "        df[\"num_new_tokens\"] = df[\"batch_size\"]\n",
    "        df[\"prod_ext_ctx\"] = df[\"batch_size\"] * df[\"input_len\"]\n",
    "        df[\"num_context_tokens\"] = df[\"batch_size\"] * df[\"input_len\"]\n",
    "        df[\"time\"] = df[\"latency\"]\n",
    "    else:\n",
    "        raise ValueError(\"stage must be either 'prefill' or 'decode'\")\n",
    "\n",
    "    return df[\n",
    "        [\"num_new_tokens\", \"prod_ext_ctx\", \"num_context_tokens\", \"batch_size\", \"time\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "def train_linear_predictor(train_df: pd.DataFrame, name):\n",
    "    \"\"\"\n",
    "    Train a linear regression model to predict latency based on engineered features.\n",
    "    \"\"\"\n",
    "    X_train = train_df[\n",
    "        [\"num_new_tokens\", \"prod_ext_ctx\", \"num_context_tokens\", \"batch_size\"]\n",
    "    ].to_numpy(dtype=np.float32)\n",
    "    y_train = train_df[\"time\"].to_numpy(dtype=np.float32)\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_lr = lr_model.predict(X_train)\n",
    "\n",
    "    print(f\"Linear Regression: {name}\")\n",
    "    print(f\"Train RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_lr)) * 1000:.2f}ms\")\n",
    "    print(f\"Train MAE: {mean_absolute_error(y_train, y_pred_lr) * 1000:.2f}ms\")\n",
    "    print(f\"Train R2: {r2_score(y_train, y_pred_lr):.4f}\")\n",
    "    return lr_model\n",
    "\n",
    "\n",
    "def train_tree_predictor(train_df: pd.DataFrame, name):\n",
    "    \"\"\"\n",
    "    Train a decision tree model to predict latency based on engineered features.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract features and target\n",
    "    X_train = train_df[\n",
    "        [\"num_new_tokens\", \"prod_ext_ctx\", \"num_context_tokens\", \"batch_size\"]\n",
    "    ].to_numpy(dtype=np.float32)\n",
    "    y_train = train_df[\"time\"].to_numpy(dtype=np.float32)\n",
    "\n",
    "    # Fit Decision Tree Regressor\n",
    "    tree_model = RandomForestRegressor(\n",
    "        n_estimators=10, random_state=42, min_samples_leaf=2, max_depth=12\n",
    "    )\n",
    "    tree_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred_tree = tree_model.predict(X_train)\n",
    "\n",
    "    print(f\"Decision Tree: {name}\")\n",
    "    print(\n",
    "        f\"Train RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_tree)) * 1000:.2f}ms\"\n",
    "    )\n",
    "    print(f\"Train MAE: {mean_absolute_error(y_train, y_pred_tree) * 1000:.2f}ms\")\n",
    "    print(f\"Train R2: {r2_score(y_train, y_pred_tree):.4f}\")\n",
    "    return tree_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "18eccb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the 'batch_lens' column into a plain Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "254305b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_prefill = build_stage_features(prefill_df, stage=\"prefill\")\n",
    "train_df_decode = build_stage_features(decode_df, stage=\"decode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "62f93227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: prefill\n",
      "Train RMSE: 43.24ms\n",
      "Train MAE: 31.27ms\n",
      "Train R2: 0.3100\n",
      "Linear Regression: decode\n",
      "Train RMSE: 1.38ms\n",
      "Train MAE: 0.92ms\n",
      "Train R2: 0.5974\n"
     ]
    }
   ],
   "source": [
    "lr_model_prefill = train_linear_predictor(train_df_prefill, \"prefill\")\n",
    "lr_model_decode = train_linear_predictor(train_df_decode, \"decode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "918dd7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: prefill\n",
      "Train RMSE: 20.55ms\n",
      "Train MAE: 9.81ms\n",
      "Train R2: 0.8441\n",
      "Decision Tree: decode\n",
      "Train RMSE: 0.43ms\n",
      "Train MAE: 0.05ms\n",
      "Train R2: 0.9619\n"
     ]
    }
   ],
   "source": [
    "tr_model_prefill = train_tree_predictor(train_df_prefill, \"prefill\")\n",
    "tr_model_decode = train_tree_predictor(train_df_decode, \"decode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250eaf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[prefill] training rows = 5661 validation rows = 58\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "MAE",
         "type": "scatter",
         "x": {
          "bdata": "0SLb+X6jgEAAAAAAQO2YQAAAAABgxKRAAAAAACASrUAAAAAA8K+yQAAAAADQ1rZAAAAAALD9ukAAAAAAkCS/QA==",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AW/am10d6T8Aki3WeXjZP6Dtj9pc9AJAoHb0D+/J7T8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H9AAqXas1zuPw==",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "colorbar": {
          "len": 0.5,
          "title": {
           "text": "MAE (ms)"
          },
          "y": 0.75,
          "yanchor": "middle"
         },
         "type": "heatmap",
         "x": [
          "(-7.503, 532.438]",
          "(532.438, 1063.875]",
          "(1595.312, 2126.75]",
          "(2658.188, 3189.625]",
          "(3189.625, 3721.062]",
          "(3721.062, 4252.5]",
          "(7441.125, 7972.562]",
          "(7972.562, 8504.0]"
         ],
         "xaxis": "x2",
         "y": [
          "(0.873, 8.938]",
          "(8.938, 16.875]",
          "(24.812, 32.75]",
          "(40.688, 48.625]",
          "(56.562, 64.5]",
          "(64.5, 72.438]",
          "(80.375, 88.312]",
          "(120.062, 128.0]"
         ],
         "yaxis": "y2",
         "z": {
          "bdata": "yV7npb/14j8gBfUOXCXXPwAAAAAAAPh/oO2P2lz0AkBAQRjysxb7PwCr4e7YmcU/AAAAAAAA+H/AkRSjczn6P6yy45euXdE/AAAAAAAA+H8Adt+3m5ncPwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwDCQd4AjdA/AAAAAAAA+H+ASXV8ozyzPwAL/ON+U9U/gP7C3AsN5T8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AHbVXK0yqT8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4f+BMo6tAV8Y/gIe85jTX3j8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8y27qFIp8SQAAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/41uFiDXP4z8gstCjUdniPwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwgjZT9RBvI/AAAAAAAA+H8ADI1E6Na2PwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8=",
          "dtype": "f8",
          "shape": "8, 8"
         }
        },
        {
         "mode": "markers+lines",
         "name": "Normalized MAE by Avg Seq Len",
         "type": "scatter",
         "x": {
          "bdata": "0SLb+X6jgEAAAAAAQO2YQAAAAABgxKRAAAAAACASrUAAAAAA8K+yQAAAAADQ1rZAAAAAALD9ukAAAAAAkCS/QA==",
          "dtype": "f8"
         },
         "xaxis": "x3",
         "y": {
          "bdata": "cti6gJdeFUCUgNcfHUj7P0NJncLUzB1AOZLaxtSKAUAAAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8UgIZ3jvvwPw==",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "cells": {
          "values": [
           [
            "RMSE",
            "MAE",
            "R²"
           ],
           [
            "3.02",
            "0.73",
            "1.00"
           ],
           [
            "2.48",
            "0.80",
            "1.00"
           ]
          ]
         },
         "domain": {
          "x": [
           0.6000000000000001,
           1
          ],
          "y": [
           0.4,
           0.6
          ]
         },
         "header": {
          "values": [
           "Metric",
           "Train",
           "Validation"
          ]
         },
         "type": "table"
        },
        {
         "mode": "markers+lines",
         "name": "MAE vs Batch Size",
         "type": "scatter",
         "x": {
          "bdata": "AQACAAQABQAIABAAIAAwAEAASABUAIAA",
          "dtype": "i2"
         },
         "xaxis": "x4",
         "y": {
          "bdata": "K/JBu6875z91b+c2oPvjP9PD3r/ahOQ/IAfOads/AEAtwin1BS3WPx2r8ig5GtM/y8jffuq+1j8AdtVcrTKpP1Wbnj1Ftso/Mtu6hSKfEkCHdL9r9IjjP8jzrcO/c+M/",
          "dtype": "f8"
         },
         "yaxis": "y4"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "MAE vs. Sequence Length",
          "x": 0.2,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "MAE Heatmap",
          "x": 0.8,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Normalized MAE vs. SeqLen",
          "x": 0.2,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Metrics",
          "x": 0.8,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "MAE vs. Batch Size",
          "x": 0.2,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.2,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 950,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 80
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "prefill lgm deepseek_ai_DeepSeek_R1_Distill_Qwen_1.5B_TP_1 Simulation Accuracy"
        },
        "width": 1050,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.4
         ],
         "title": {
          "text": "Seq Length"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.6000000000000001,
          1
         ],
         "tickangle": -45,
         "title": {
          "text": "Seq Length"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.4
         ],
         "title": {
          "text": "Seq Length"
         }
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0,
          0.4
         ],
         "title": {
          "text": "Batch Size"
         }
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0.6000000000000001,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.8,
          1
         ],
         "title": {
          "text": "MAE (ms)"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.8,
          1
         ],
         "title": {
          "text": "Batch Size"
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.4,
          0.6
         ],
         "title": {
          "text": "Error (%)"
         }
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.2
         ],
         "title": {
          "text": "MAE (ms)"
         }
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.2
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[decode] training rows = 4939 validation rows = 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "MAE",
         "type": "scatter",
         "x": {
          "bdata": "okW28/0me0AAAAAAQD2UQAAAAABg2KBAAAAAACCSp0AAAAAA4EuuQAAAAADQgrJAAAAAALDftUAAAAAAkDy5QA==",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "mo+7F/zylz8AAAAAAAD4f6upHYBp95M/FgIi8EENfj+X3nQD8GiePwAAAAAAAPh/AGChLCUCRT8Abjz0HWt+Pw==",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "colorbar": {
          "len": 0.5,
          "title": {
           "text": "MAE (ms)"
          },
          "y": 0.75,
          "yanchor": "middle"
         },
         "type": "heatmap",
         "x": [
          "(-2.887, 434.438]",
          "(434.438, 864.875]",
          "(2156.188, 2586.625]",
          "(2586.625, 3017.062]",
          "(3017.062, 3447.5]",
          "(3447.5, 3877.938]",
          "(3877.938, 4308.375]",
          "(5599.688, 6030.125]",
          "(6030.125, 6460.562]",
          "(6460.562, 6891.0]"
         ],
         "xaxis": "x2",
         "y": [
          "(0.821, 12.188]",
          "(12.188, 23.375]",
          "(23.375, 34.562]",
          "(45.75, 56.938]",
          "(56.938, 68.125]",
          "(68.125, 79.312]",
          "(90.5, 101.688]",
          "(124.062, 135.25]",
          "(168.812, 180.0]"
         ],
         "yaxis": "y2",
         "z": {
          "bdata": "ACXx82TDcz+AIvZygDaVP4DFzUjbVpE/kihlV/WihD+AX7gceCR5PyBspo7EOKU/AAAAAAAA+H8AYKEsJQJFPwCsBEEpbns/AAAAAAAA+H+ADPZwtj+oPwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AGzorsPMej8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AGLpTCbSAPwAavDsjoak/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/QPfTam/2uT8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AzCXYUgydPwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8A/AwOLnuFPwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwDvpoKu1a4/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AESDj8qCmD8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AHK97oU4mT8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwASFuEuwIw/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/",
          "dtype": "f8",
          "shape": "9, 10"
         }
        },
        {
         "mode": "markers+lines",
         "name": "Normalized MAE by Avg Seq Len",
         "type": "scatter",
         "x": {
          "bdata": "okW28/0me0AAAAAAQD2UQAAAAABg2KBAAAAAACCSp0AAAAAA4EuuQAAAAADQgrJAAAAAALDftUAAAAAAkDy5QA==",
          "dtype": "f8"
         },
         "xaxis": "x3",
         "y": {
          "bdata": "BfHDVDXZ0j8AAAAAAAD4fxKBEn2Rbc8/Y9Dlm7+mtz/jktAH5+7XPwAAAAAAAPh/Lo+JXrWIgD8o6RUknvC3Pw==",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "cells": {
          "values": [
           [
            "RMSE",
            "MAE",
            "R²"
           ],
           [
            "0.38",
            "0.03",
            "0.97"
           ],
           [
            "0.03",
            "0.02",
            "1.00"
           ]
          ]
         },
         "domain": {
          "x": [
           0.6000000000000001,
           1
          ],
          "y": [
           0.4,
           0.6
          ]
         },
         "header": {
          "values": [
           "Metric",
           "Train",
           "Validation"
          ]
         },
         "type": "table"
        },
        {
         "mode": "markers+lines",
         "name": "MAE vs Batch Size",
         "type": "scatter",
         "x": {
          "bdata": "AQACAAMABAAFAAYABwAIAAkACwAQABEAEwAVABYAIAAyAD4AQABGAFsAgACxALQA",
          "dtype": "i2"
         },
         "xaxis": "x4",
         "y": {
          "bdata": "q/LLoAdsgz9dARbHXICLPwBAk/KCR0A/AHiEpDcZjD8AIPUEJuRyPwAQ/AINrXA/AExPKoq7dD8z17Z1tAmHPwBWdGF50WU/ADTdLSuEij+ADPZwtj+oPwAYulMJtIA/AJjKiQE9cD8AYG+2RwZQPwBqqcrbE44/ABq8OyOhqT9A99Nqb/a5PwD8DA4ue4U/AMwl2FIMnT8A76aCrtWuPwBEg4/Kgpg/AHK97oU4mT8AYOkN/PBnPwDmWF8Pwpk/",
          "dtype": "f8"
         },
         "yaxis": "y4"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "MAE vs. Sequence Length",
          "x": 0.2,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "MAE Heatmap",
          "x": 0.8,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Normalized MAE vs. SeqLen",
          "x": 0.2,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Metrics",
          "x": 0.8,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "MAE vs. Batch Size",
          "x": 0.2,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.2,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 950,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 80
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "decode lgm deepseek_ai_DeepSeek_R1_Distill_Qwen_1.5B_TP_1 Simulation Accuracy"
        },
        "width": 1050,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.4
         ],
         "title": {
          "text": "Seq Length"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.6000000000000001,
          1
         ],
         "tickangle": -45,
         "title": {
          "text": "Seq Length"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.4
         ],
         "title": {
          "text": "Seq Length"
         }
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0,
          0.4
         ],
         "title": {
          "text": "Batch Size"
         }
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0.6000000000000001,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.8,
          1
         ],
         "title": {
          "text": "MAE (ms)"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.8,
          1
         ],
         "title": {
          "text": "Batch Size"
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.4,
          0.6
         ],
         "title": {
          "text": "Error (%)"
         }
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.2
         ],
         "title": {
          "text": "MAE (ms)"
         }
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.2
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from llm_execution_time_predictor.train_utils import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "def batch_size_regime(batch_size):\n",
    "    if batch_size < 30:\n",
    "        return 0  # Small\n",
    "    elif batch_size < 100:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "def seq_len_regime(seq_len):\n",
    "    if seq_len < 512:\n",
    "        return 0  # Short\n",
    "    elif seq_len < 2048:\n",
    "        return 1\n",
    "    elif seq_len < 8192:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "\n",
    "def build_stage_features(df: pd.DataFrame, *, stage: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create latency-prediction features for *one* stage (“prefill” or “decode”).\n",
    "    The function expects df to contain list-typed columns:\n",
    "      combined_seq_lens, cached_prefix_lens, new_extend_lens\n",
    "    plus scalar columns batch_size, latency, total_token_length, cache_percent.\n",
    "    \"\"\"\n",
    "    if stage not in (\"prefill\", \"decode\"):\n",
    "        raise ValueError(\"stage must be 'prefill' or 'decode'\")\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    _lst = lambda x: x if isinstance(x, (list, tuple, np.ndarray)) else [x]\n",
    "\n",
    "    df[\"len_max\"] = df[\"combined_seq_lens\"].apply(lambda x: np.max(_lst(x)))\n",
    "    df[\"len_min\"] = df[\"combined_seq_lens\"].apply(lambda x: np.min(_lst(x)))\n",
    "    df[\"len_std\"] = df[\"combined_seq_lens\"].apply(lambda x: np.std(_lst(x)))\n",
    "    df[\"len_p90\"] = df[\"combined_seq_lens\"].apply(lambda x: np.percentile(_lst(x), 90))\n",
    "    df[\"len_p95\"] = df[\"combined_seq_lens\"].apply(lambda x: np.percentile(_lst(x), 95))\n",
    "\n",
    "    df[\"cached_sum\"] = df[\"cached_prefix_lens\"].apply(lambda x: np.sum(_lst(x)))\n",
    "    df[\"cached_max\"] = df[\"cached_prefix_lens\"].apply(lambda x: np.max(_lst(x)))\n",
    "    df[\"cached_ratio\"] = df[\"cached_sum\"] / df[\"total_token_length\"].clip(lower=1)\n",
    "\n",
    "    df[\"extend_sum\"] = df[\"new_extend_lens\"].apply(lambda x: np.sum(_lst(x)))\n",
    "    df[\"extend_max\"] = df[\"new_extend_lens\"].apply(lambda x: np.max(_lst(x)))\n",
    "    df[\"extend_mean\"] = df[\"new_extend_lens\"].apply(lambda x: np.mean(_lst(x)))\n",
    "    df[\"extend_std\"] = df[\"new_extend_lens\"].apply(lambda x: np.std(_lst(x)))\n",
    "    df[\"extend_p90\"] = df[\"new_extend_lens\"].apply(lambda x: np.percentile(_lst(x), 90))\n",
    "\n",
    "    df[\"imbalance\"] = df[\"len_max\"] / df[\"len_min\"].replace(0, np.nan)\n",
    "    df[\"cache_percent\"] = df.get(\"cache_percent\", np.nan)\n",
    "    if stage == \"prefill\":\n",
    "        df[\"num_new_tokens\"] = df[\"extend_sum\"]\n",
    "        df[\"prod_ext_ctx\"] = df[\"batch_size\"] * (df[\"len_max\"] ** 2)\n",
    "    else:\n",
    "        df[\"num_new_tokens\"] = df[\"batch_size\"]\n",
    "        df[\"prod_ext_ctx\"] = df[\"batch_size\"] * df[\"len_max\"]\n",
    "\n",
    "    df[\"num_context_tokens\"] = df[\"batch_size\"] * df[\"len_max\"]\n",
    "    df[\"time\"] = df[\"latency\"]\n",
    "\n",
    "    df[\"len_mean\"] = df[\"combined_seq_lens\"].apply(lambda x: np.mean(_lst(x)))\n",
    "    df[\"len_median\"] = df[\"combined_seq_lens\"].apply(lambda x: np.median(_lst(x)))\n",
    "    df[\"len_range\"] = df[\"len_max\"] - df[\"len_min\"]\n",
    "    df[\"len_p99\"] = df[\"combined_seq_lens\"].apply(lambda x: np.percentile(_lst(x), 99))\n",
    "    df[\"len_cv\"] = df[\"len_std\"] / df[\"len_mean\"].clip(lower=1)\n",
    "\n",
    "    df[\"extend_min\"] = df[\"new_extend_lens\"].apply(lambda x: np.min(_lst(x)))\n",
    "    df[\"extend_median\"] = df[\"new_extend_lens\"].apply(lambda x: np.median(_lst(x)))\n",
    "    df[\"extend_p99\"] = df[\"new_extend_lens\"].apply(lambda x: np.percentile(_lst(x), 99))\n",
    "    df[\"extend_cv\"] = df[\"extend_std\"] / df[\"extend_mean\"].clip(lower=1)\n",
    "\n",
    "    df[\"prompt_ratio\"] = df[\"extend_sum\"] / df[\"total_token_length\"].clip(lower=1)\n",
    "    df[\"cached_peak_ratio\"] = df[\"cached_max\"] / df[\"len_max\"].clip(lower=1)\n",
    "    df[\"B_len_mean\"] = df[\"batch_size\"] * df[\"len_mean\"]\n",
    "    df[\"B_len_max_sq\"] = df[\"batch_size\"] * (df[\"len_max\"] ** 2)\n",
    "    df[\"cache_len_prod\"] = df[\"cache_percent\"] * df[\"len_max\"]\n",
    "\n",
    "    for col in [\"prod_ext_ctx\", \"num_context_tokens\"]:\n",
    "        df[f\"log_{col}\"] = np.log1p(df[col])\n",
    "    df[\"normalized_skew\"] = df[\"len_std\"] / df[\"len_mean\"].clip(lower=1)\n",
    "    df[\"extend_skew\"] = df[\"extend_std\"] / df[\"extend_mean\"].clip(lower=1)\n",
    "    df[\"batch_size_regime\"] = df[\"batch_size\"].apply(batch_size_regime)\n",
    "    df[\"seq_len_regime\"] = df[\"len_max\"].apply(seq_len_regime)\n",
    "\n",
    "    keep = [\n",
    "        \"num_new_tokens\",\n",
    "        \"prod_ext_ctx\",\n",
    "        \"num_context_tokens\",\n",
    "        \"len_max\",\n",
    "        \"len_min\",\n",
    "        \"len_std\",\n",
    "        \"len_p90\",\n",
    "        \"len_p95\",\n",
    "        \"cached_sum\",\n",
    "        \"cached_max\",\n",
    "        \"cached_ratio\",\n",
    "        \"extend_max\",\n",
    "        \"extend_mean\",\n",
    "        \"extend_std\",\n",
    "        \"extend_p90\",\n",
    "        \"batch_size\",\n",
    "        \"imbalance\",\n",
    "        \"normalized_skew\",\n",
    "        \"extend_skew\",\n",
    "        \"batch_size_regime\",\n",
    "        \"seq_len_regime\",\n",
    "        \"cache_percent\",\n",
    "        \"len_mean\",\n",
    "        \"len_median\",\n",
    "        \"len_range\",\n",
    "        \"len_p99\",\n",
    "        \"len_cv\",\n",
    "        \"extend_min\",\n",
    "        \"extend_median\",\n",
    "        \"extend_p99\",\n",
    "        \"extend_cv\",\n",
    "        \"prompt_ratio\",\n",
    "        \"cached_peak_ratio\",\n",
    "        \"B_len_mean\",\n",
    "        \"B_len_max_sq\",\n",
    "        \"cache_len_prod\",\n",
    "        \"time\",\n",
    "    ]\n",
    "    return df[keep]\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "def find_closest_bin(value, bins: Dict):\n",
    "    for key, bin_val in bins.items():\n",
    "        if value <= key:\n",
    "            return bin_val\n",
    "    return bins[max(bins.keys())]\n",
    "\n",
    "\n",
    "def find_closest_bin_for_all_lens(values, bins: Dict[int, int]):\n",
    "    return [find_closest_bin(v, bins) for v in values]\n",
    "\n",
    "\n",
    "def train_tree_predictor(\n",
    "    train_df: pd.DataFrame,\n",
    "    stage: str,\n",
    "    model_type=\"lgm\",\n",
    "    train_split_eval=True,\n",
    "    model_name=\"Qwen3\",\n",
    "    latency_normalization_dict=None,\n",
    ") -> object:\n",
    "    \"\"\"\n",
    "    Dummy LightGBM regressor; swap this out with your real trainer.\n",
    "    \"\"\"\n",
    "    import lightgbm as lgb\n",
    "\n",
    "    X = train_df.drop(columns=[\"time\"])\n",
    "    y = train_df[\"time\"]\n",
    "\n",
    "    if model_type == \"lgm\":\n",
    "        model = lgb.LGBMRegressor(min_data_in_leaf=1, verbose=-1)\n",
    "    elif model_type == \"xgboost\":\n",
    "        model = xgb.XGBRegressor(\n",
    "            n_estimators=100, random_state=42, min_child_weight=1, max_depth=12\n",
    "        )\n",
    "    else:\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=10, random_state=42, min_samples_leaf=2, max_depth=12\n",
    "        )\n",
    "    if train_split_eval:\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.01, random_state=42\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        print(\n",
    "            f\"[{stage}] training rows =\", len(X_train), \"validation rows =\", len(X_val)\n",
    "        )\n",
    "\n",
    "        train_pred = model.predict(X_train)\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, train_pred)) * 1000\n",
    "        train_mae = mean_absolute_error(y_train, train_pred) * 1000\n",
    "        train_r2 = r2_score(y_train, train_pred)\n",
    "\n",
    "        val_pred = model.predict(X_val)\n",
    "        val_rmse = np.sqrt(mean_squared_error(y_val, val_pred)) * 1000\n",
    "        val_mae = mean_absolute_error(y_val, val_pred) * 1000\n",
    "        val_r2 = r2_score(y_val, val_pred)\n",
    "\n",
    "        df_eval = pd.DataFrame(\n",
    "            {\n",
    "                \"true\": y_val * 1000,\n",
    "                \"pred\": val_pred * 1000,\n",
    "                \"len_max\": X_val[\"len_max\"],\n",
    "                \"batch_size\": X_val[\"batch_size\"],\n",
    "            }\n",
    "        )\n",
    "        df_eval[\"error_ms\"] = (df_eval[\"true\"] - df_eval[\"pred\"]).abs()\n",
    "        min_len = df_eval[\"len_max\"].min()\n",
    "        max_len = df_eval[\"len_max\"].max()\n",
    "        n_bins = 8\n",
    "        bins = np.linspace(min_len, max_len, n_bins + 1)\n",
    "        df_eval[\"len_bin\"] = pd.cut(df_eval[\"len_max\"], bins=bins, include_lowest=True)\n",
    "        df_eval[\"len_bin_str\"] = df_eval[\"len_bin\"].astype(str)\n",
    "\n",
    "        mae_by_len = (\n",
    "            df_eval.groupby(\"len_bin\", observed=False)[\"error_ms\"].mean().reset_index()\n",
    "        )\n",
    "        mae_by_len[\"len_center\"] = mae_by_len[\"len_bin\"].apply(\n",
    "            lambda x: (x.left + x.right) / 2\n",
    "        )\n",
    "        mae_by_len[\"len_bin_str\"] = mae_by_len[\"len_bin\"].astype(str)\n",
    "        df_eval[\"bs_bin\"] = pd.cut(df_eval[\"batch_size\"], bins=16)\n",
    "        df_eval[\"len_bin2\"] = pd.cut(df_eval[\"len_max\"], bins=16)\n",
    "        df_eval[\"bs_bin_str\"] = pd.Categorical(\n",
    "            df_eval[\"bs_bin\"].astype(str),\n",
    "            categories=[str(cat) for cat in df_eval[\"bs_bin\"].cat.categories],\n",
    "            ordered=True,\n",
    "        )\n",
    "\n",
    "        df_eval[\"len_bin2_str\"] = pd.Categorical(\n",
    "            df_eval[\"len_bin2\"].astype(str),\n",
    "            categories=[str(cat) for cat in df_eval[\"len_bin2\"].cat.categories],\n",
    "            ordered=True,\n",
    "        )\n",
    "        mae_by_len[\"error_ms_percent\"] = [\n",
    "            (\n",
    "                mae_by_len.iloc[i][\"error_ms\"]\n",
    "                / find_closest_bin(\n",
    "                    mae_by_len.iloc[i][\"len_center\"], latency_normalization_dict\n",
    "                )\n",
    "            )\n",
    "            * 100\n",
    "            for i in range(len(mae_by_len))\n",
    "        ]\n",
    "\n",
    "        mae_by_bs = (\n",
    "            df_eval.groupby(\"batch_size\", observed=False)[\"error_ms\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        pivot = df_eval.pivot_table(\n",
    "            index=\"bs_bin_str\",\n",
    "            columns=\"len_bin2_str\",\n",
    "            values=\"error_ms\",\n",
    "            aggfunc=\"mean\",\n",
    "            observed=False,\n",
    "        )\n",
    "\n",
    "        fig = make_subplots(\n",
    "            rows=3,\n",
    "            cols=2,\n",
    "            specs=[\n",
    "                [{\"type\": \"xy\"}, {\"type\": \"xy\"}],\n",
    "                [{\"type\": \"xy\"}, {\"type\": \"domain\"}],\n",
    "                [{\"type\": \"xy\"}, {\"type\": \"xy\"}],\n",
    "            ],\n",
    "            subplot_titles=(\n",
    "                \"MAE vs. Sequence Length\",\n",
    "                \"MAE Heatmap\",\n",
    "                \"Normalized MAE vs. SeqLen\",\n",
    "                \"Metrics\",\n",
    "                \"MAE vs. Batch Size\",\n",
    "                \"\",\n",
    "            ),\n",
    "            horizontal_spacing=0.2,\n",
    "            vertical_spacing=0.20,\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=mae_by_len[\"len_center\"],\n",
    "                y=mae_by_len[\"error_ms\"],\n",
    "                mode=\"markers+lines\",\n",
    "                name=\"MAE\",\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "        fig.update_xaxes(title_text=\"Seq Length\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"MAE (ms)\", row=1, col=1)\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Heatmap(\n",
    "                z=pivot.values,\n",
    "                x=pivot.columns,\n",
    "                y=pivot.index,\n",
    "                colorbar=dict(title=\"MAE (ms)\", len=0.5, y=0.75, yanchor=\"middle\"),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=2,\n",
    "        )\n",
    "        fig.update_xaxes(title_text=\"Seq Length\", row=1, col=2, tickangle=-45)\n",
    "        fig.update_yaxes(title_text=\"Batch Size\", row=1, col=2)\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=mae_by_len[\"len_center\"],\n",
    "                y=mae_by_len[\"error_ms_percent\"],\n",
    "                mode=\"markers+lines\",\n",
    "                name=\"Normalized MAE by Avg Seq Len\",\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "        fig.update_xaxes(title_text=\"Seq Length\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Error (%)\", row=2, col=1)\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Table(\n",
    "                header=dict(values=[\"Metric\", \"Train\", \"Validation\"]),\n",
    "                cells=dict(\n",
    "                    values=[\n",
    "                        [\"RMSE\", \"MAE\", \"R²\"],\n",
    "                        [f\"{train_rmse:.2f}\", f\"{train_mae:.2f}\", f\"{train_r2:.2f}\"],\n",
    "                        [f\"{val_rmse:.2f}\", f\"{val_mae:.2f}\", f\"{val_r2:.2f}\"],\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            row=2,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=mae_by_bs[\"batch_size\"],\n",
    "                y=mae_by_bs[\"error_ms\"],\n",
    "                mode=\"markers+lines\",\n",
    "                name=\"MAE vs Batch Size\",\n",
    "            ),\n",
    "            row=3,\n",
    "            col=1,\n",
    "        )\n",
    "        fig.update_xaxes(title_text=\"Batch Size\", row=3, col=1)\n",
    "        fig.update_yaxes(title_text=\"MAE (ms)\", row=3, col=1)\n",
    "\n",
    "        fig.update_layout(\n",
    "            height=950,\n",
    "            width=1050,\n",
    "            title_text=f\"{stage} {model_type} {model_name} Simulation Accuracy\",\n",
    "            showlegend=False,\n",
    "            margin=dict(l=50, r=50, t=80, b=50),\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "    else:\n",
    "        model.fit(X, y)\n",
    "        print(f\"[{stage}] training rows =\", len(train_df))\n",
    "\n",
    "        y_pred = model.predict(X)\n",
    "        rmse = np.sqrt(mean_squared_error(y, y_pred)) * 1000  # → milliseconds\n",
    "        mae = mean_absolute_error(y, y_pred) * 1000  # → milliseconds\n",
    "        r2 = r2_score(y, y_pred)\n",
    "\n",
    "        print(f\"[{stage}] {model_type} {model_name}\")\n",
    "        print(f\"  Train RMSE: {rmse:.2f} ms\")\n",
    "        print(f\"  Train MAE : {mae:.2f} ms\")\n",
    "        print(f\"  Train R²  : {r2:.4f}\")\n",
    "        # Iteratively drop the least important feature, printing RMSE after each drop.\n",
    "        # Label drops that increase RMSE by more than 1% from the previous step.\n",
    "        # if hasattr(model, \"feature_importances_\"):\n",
    "        #     importances = model.feature_importances_\n",
    "        #     feature_names = list(X.columns)\n",
    "        #     X_iter = X.copy()\n",
    "        #     y_true = y\n",
    "        #     model.fit(X_iter, y_true)\n",
    "        #     y_pred = model.predict(X_iter)\n",
    "        #     prev_rmse = np.sqrt(mean_squared_error(y_true, y_pred)) * 1000\n",
    "        #     print(f\"Initial RMSE: {prev_rmse:.2f} ms\")\n",
    "        #     features_to_drop = []\n",
    "        #     for i in range(20):\n",
    "        #         # Fit and get importances for current features\n",
    "        #         model.fit(X_iter, y_true)\n",
    "        #         importances = model.feature_importances_\n",
    "        #         least_idx = np.argmin(importances)\n",
    "        #         least_feature = X_iter.columns[least_idx]\n",
    "        #         features_to_drop.append(least_feature)\n",
    "        #         X_iter = X_iter.drop(columns=[least_feature])\n",
    "        #         model.fit(X_iter, y_true)\n",
    "        #         y_pred = model.predict(X_iter)\n",
    "        #         new_rmse = np.sqrt(mean_squared_error(y_true, y_pred)) * 1000\n",
    "        #         diff_pct = 100 * (new_rmse - prev_rmse) / prev_rmse if prev_rmse != 0 else 0\n",
    "        #         label = \"\"\n",
    "        #         if abs(diff_pct) > 1:\n",
    "        #             label = \" [>1% RMSE change]\"\n",
    "        #         print(f\"After dropping '{least_feature}': RMSE = {new_rmse:.2f} ms (Δ {diff_pct:+.2f}%){label}\")\n",
    "        #         prev_rmse = new_rmse\n",
    "        #     print(f\"Dropped features: {features_to_drop}\")\n",
    "        #     # Optionally, refit model on reduced features for return\n",
    "        #     model.fit(X_iter, y_true)\n",
    "        #\n",
    "    return model\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3.  End-to-end pipeline\n",
    "# ---------------------------------------------------------------------\n",
    "def train_latency_models(\n",
    "    raw_df: pd.DataFrame, model_type=\"lgm\", train_split_eval=True, model_name=\"Qwen3\"\n",
    ") -> Tuple:\n",
    "    \"\"\"\n",
    "    Preprocess → feature-engineer → train separate tree models for\n",
    "    prefill and decode.  Returns (prefill_model, decode_model).\n",
    "    \"\"\"\n",
    "    df = raw_df.copy()\n",
    "\n",
    "    # fill in total_extend_len if missing\n",
    "    df[\"total_extend_len\"] = df[\"total_extend_len\"].fillna(\n",
    "        df[\"new_extend_lens\"].apply(sum)\n",
    "    )\n",
    "\n",
    "    # ensure list-typed columns stay lists when reading from CSV\n",
    "    list_cols = [\"combined_seq_lens\", \"cached_prefix_lens\", \"new_extend_lens\"]\n",
    "    for c in list_cols:\n",
    "        df[c] = df[c].apply(lambda v: v if isinstance(v, list) else eval(v))\n",
    "\n",
    "    # split by stage\n",
    "    prefill_df = df[df[\"forward_mode\"] == \"prefill\"]\n",
    "    decode_df = df[df[\"forward_mode\"] == \"decode\"]\n",
    "\n",
    "    # build features\n",
    "    train_df_prefill = build_stage_features(prefill_df, stage=\"prefill\")\n",
    "    train_df_decode = build_stage_features(decode_df, stage=\"decode\")\n",
    "    forward_mode_to_filter = \"prefill\"\n",
    "    df_bs1_prefill = (\n",
    "        combined_df[\n",
    "            (combined_df[\"batch_size\"] == 1)\n",
    "            & (combined_df[\"skew\"] == 0)\n",
    "            & (combined_df[\"forward_mode\"] == forward_mode_to_filter)\n",
    "            & (combined_df[\"cache_percent\"] == 0.0)\n",
    "        ]\n",
    "        .filter([\"total_token_length\", \"latency\"])\n",
    "        .set_index(\"total_token_length\")\n",
    "        * 1000\n",
    "    )\n",
    "\n",
    "    prefill_latency_for_normalization = df_bs1_prefill.to_dict()[\"latency\"]\n",
    "    forward_mode_to_filter = \"decode\"\n",
    "    decode_bs_base = (\n",
    "        combined_df[\n",
    "            (combined_df[\"skew\"] == 0)\n",
    "            & (combined_df[\"forward_mode\"] == forward_mode_to_filter)\n",
    "            & (combined_df[\"total_token_length\"] > 500)\n",
    "        ]\n",
    "        .groupby(\"batch_size\")[\"latency\"]\n",
    "        .mean()\n",
    "        * 1000\n",
    "    )\n",
    "    decode_latency_for_normalization = decode_bs_base.to_dict()\n",
    "\n",
    "    # train tree models\n",
    "    model_prefill = train_tree_predictor(\n",
    "        train_df_prefill,\n",
    "        \"prefill\",\n",
    "        model_type=model_type,\n",
    "        train_split_eval=train_split_eval,\n",
    "        model_name=model_name,\n",
    "        latency_normalization_dict=prefill_latency_for_normalization,\n",
    "    )\n",
    "    model_decode = train_tree_predictor(\n",
    "        train_df_decode,\n",
    "        \"decode\",\n",
    "        model_type=model_type,\n",
    "        train_split_eval=train_split_eval,\n",
    "        model_name=model_name,\n",
    "        latency_normalization_dict=decode_latency_for_normalization,\n",
    "    )\n",
    "    return model_prefill, model_decode\n",
    "\n",
    "\n",
    "model_prefill, model_decode = train_latency_models(\n",
    "    combined_df, model_type=\"lgm\", train_split_eval=True, model_name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682a6203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "833ea220",
   "metadata": {},
   "source": [
    "<!-- [prefill] RandomForest\n",
    "Train RMSE: 0.08 ms\n",
    "Train MAE : 0.94 ms\n",
    "Train R²  : 1.00\n",
    "Val   RMSE: 0.04 ms\n",
    "Val   MAE : 0.74 ms\n",
    "Val   R²  : 1.00\n",
    "[decode] RandomForest\n",
    "Train RMSE: 0.03 ms\n",
    "Train MAE : 0.08 ms\n",
    "Train R²  : 0.99\n",
    "Val   RMSE: 0.06 ms\n",
    "Val   MAE : 0.27 ms\n",
    "Val   R²  : 0.95 -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0dc30ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [prefill] RandomForest\n",
    "# Train RMSE: 0.08 ms\n",
    "# Train MAE : 0.94 ms\n",
    "# Train R²  : 1.00\n",
    "# Val   RMSE: 0.04 ms\n",
    "# Val   MAE : 0.74 ms\n",
    "# Val   R²  : 1.00\n",
    "# [decode] RandomForest\n",
    "# Train RMSE: 0.03 ms\n",
    "# Train MAE : 0.08 ms\n",
    "# Train R²  : 0.99\n",
    "# Val   RMSE: 0.06 ms\n",
    "# Val   MAE : 0.27 ms\n",
    "# Val   R²  : 0.95\n",
    "\n",
    "# [prefill] LGBM\n",
    "# Train RMSE: 0.03 ms\n",
    "# Train MAE : 0.59 ms\n",
    "# Train R²  : 1.00\n",
    "# Val   RMSE: 0.03 ms\n",
    "# Val   MAE : 0.58 ms\n",
    "# Val   R²  : 1.00\n",
    "# [decode] LGBM\n",
    "# Train RMSE: 0.00 ms\n",
    "# Train MAE : 0.05 ms\n",
    "# Train R²  : 1.00\n",
    "# Val   RMSE: 0.00 ms\n",
    "# Val   MAE : 0.05 ms\n",
    "# Val   R²  : 1.00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8f404d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import powerlaw\n",
    "# dic = {\"batch_size\": 256, \"total_token_length\": 16384, \"skew\": 1.5, \"combined_seq_lens\": [6587, 2329, 1268, 823, 589, 448, 356, 291, 244, 208, 181, 158, 140, 126, 113, 103, 94, 86, 79, 74, 68, 64, 60, 56, 53, 50, 47, 44, 42, 40, 38, 36, 35, 33, 32, 30, 29, 28, 27, 26, 25, 24, 23, 23, 22, 21, 20, 20, 19, 19, 18, 18, 17, 17, 16, 16, 15, 15, 15, 14, 14, 13, 13, 13, 13, 12, 12, 12, 11, 11, 11, 11, 11, 10, 10, 10, 10, 10, 9, 9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], \"cached_prefix_lens\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"new_extend_lens\": [6587, 2329, 1268, 823, 589, 448, 356, 291, 244, 208, 181, 158, 140, 126, 113, 103, 94, 86, 79, 74, 68, 64, 60, 56, 53, 50, 47, 44, 42, 40, 38, 36, 35, 33, 32, 30, 29, 28, 27, 26, 25, 24, 23, 23, 22, 21, 20, 20, 19, 19, 18, 18, 17, 17, 16, 16, 15, 15, 15, 14, 14, 13, 13, 13, 13, 12, 12, 12, 11, 11, 11, 11, 11, 10, 10, 10, 10, 10, 9, 9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], \"total_extend_len\": 16384, \"latency\": 0.6045422721654177, \"throughput\": 27101.496048099238, \"forward_mode\": \"prefill\"}\n",
    "# dic2 = {\"batch_size\": 256, \"total_token_length\": 16384, \"skew\": 1.0, \"combined_seq_lens\": [2675, 1338, 892, 669, 535, 446, 382, 334, 297, 268, 243, 223, 206, 191, 178, 167, 157, 149, 141, 134, 127, 122, 116, 111, 107, 103, 99, 96, 92, 89, 86, 84, 81, 79, 76, 74, 72, 70, 69, 67, 65, 64, 62, 61, 59, 58, 57, 56, 55, 54, 52, 51, 50, 50, 49, 48, 47, 46, 45, 45, 44, 43, 42, 42, 41, 41, 40, 39, 39, 38, 38, 37, 37, 36, 36, 35, 35, 34, 34, 33, 33, 33, 32, 32, 31, 31, 31, 30, 30, 30, 29, 29, 29, 28, 28, 28, 28, 27, 27, 27, 26, 26, 26, 26, 25, 25, 25, 25, 25, 24, 24, 24, 24, 23, 23, 23, 23, 23, 22, 22, 22, 22, 22, 22, 21, 21, 21, 21, 21, 21, 20, 20, 20, 20, 20, 20, 20, 19, 19, 19, 19, 19, 19, 19, 18, 18, 18, 18, 18, 18, 18, 18, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 10], \"cached_prefix_lens\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"new_extend_lens\": [2675, 1338, 892, 669, 535, 446, 382, 334, 297, 268, 243, 223, 206, 191, 178, 167, 157, 149, 141, 134, 127, 122, 116, 111, 107, 103, 99, 96, 92, 89, 86, 84, 81, 79, 76, 74, 72, 70, 69, 67, 65, 64, 62, 61, 59, 58, 57, 56, 55, 54, 52, 51, 50, 50, 49, 48, 47, 46, 45, 45, 44, 43, 42, 42, 41, 41, 40, 39, 39, 38, 38, 37, 37, 36, 36, 35, 35, 34, 34, 33, 33, 33, 32, 32, 31, 31, 31, 30, 30, 30, 29, 29, 29, 28, 28, 28, 28, 27, 27, 27, 26, 26, 26, 26, 25, 25, 25, 25, 25, 24, 24, 24, 24, 23, 23, 23, 23, 23, 22, 22, 22, 22, 22, 22, 21, 21, 21, 21, 21, 21, 20, 20, 20, 20, 20, 20, 20, 19, 19, 19, 19, 19, 19, 19, 18, 18, 18, 18, 18, 18, 18, 18, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 10], \"total_extend_len\": 16384, \"latency\": 0.5496579594910145, \"throughput\": 29807.62802956888, \"forward_mode\": \"prefill\"}\n",
    "# dic3 = {\"batch_size\": 256, \"total_token_length\": 16384, \"skew\": 0.5, \"combined_seq_lens\": [536, 379, 309, 268, 240, 219, 203, 189, 179, 169, 162, 155, 149, 143, 138, 134, 130, 126, 123, 120, 117, 114, 112, 109, 107, 105, 103, 101, 100, 98, 96, 95, 93, 92, 91, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 77, 76, 75, 74, 74, 73, 72, 72, 71, 70, 70, 69, 69, 68, 68, 67, 66, 66, 65, 65, 65, 64, 64, 63, 63, 62, 62, 61, 61, 61, 60, 60, 60, 59, 59, 58, 58, 58, 57, 57, 57, 56, 56, 56, 56, 55, 55, 55, 54, 54, 54, 54, 53, 53, 53, 53, 52, 52, 52, 52, 51, 51, 51, 51, 50, 50, 50, 50, 50, 49, 49, 49, 49, 49, 48, 48, 48, 48, 48, 47, 47, 47, 47, 47, 46, 46, 46, 46, 46, 46, 45, 45, 45, 45, 45, 45, 44, 44, 44, 44, 44, 44, 44, 43, 43, 43, 43, 43, 43, 43, 42, 42, 42, 42, 42, 42, 42, 42, 41, 41, 41, 41, 41, 41, 41, 41, 41, 40, 40, 40, 40, 40, 40, 40, 40, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 33], \"cached_prefix_lens\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"new_extend_lens\": [536, 379, 309, 268, 240, 219, 203, 189, 179, 169, 162, 155, 149, 143, 138, 134, 130, 126, 123, 120, 117, 114, 112, 109, 107, 105, 103, 101, 100, 98, 96, 95, 93, 92, 91, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 77, 76, 75, 74, 74, 73, 72, 72, 71, 70, 70, 69, 69, 68, 68, 67, 66, 66, 65, 65, 65, 64, 64, 63, 63, 62, 62, 61, 61, 61, 60, 60, 60, 59, 59, 58, 58, 58, 57, 57, 57, 56, 56, 56, 56, 55, 55, 55, 54, 54, 54, 54, 53, 53, 53, 53, 52, 52, 52, 52, 51, 51, 51, 51, 50, 50, 50, 50, 50, 49, 49, 49, 49, 49, 48, 48, 48, 48, 48, 47, 47, 47, 47, 47, 46, 46, 46, 46, 46, 46, 45, 45, 45, 45, 45, 45, 44, 44, 44, 44, 44, 44, 44, 43, 43, 43, 43, 43, 43, 43, 42, 42, 42, 42, 42, 42, 42, 42, 41, 41, 41, 41, 41, 41, 41, 41, 41, 40, 40, 40, 40, 40, 40, 40, 40, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 33], \"total_extend_len\": 16384, \"latency\": 0.5343855218961835, \"throughput\": 30659.51327023969, \"forward_mode\": \"prefill\"}\n",
    "# dic4 = {\"batch_size\": 256, \"total_token_length\": 16384, \"skew\": 0, \"combined_seq_lens\": [64.01, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64], \"cached_prefix_lens\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"new_extend_lens\": [64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64], \"total_extend_len\": 16384, \"latency\": 0.5322961853817105, \"throughput\": 30779.856121364097, \"forward_mode\": \"prefill\"}\n",
    "\n",
    "# import numpy as np\n",
    "# from collections import Counter\n",
    "\n",
    "# def shannon_entropy(lst):\n",
    "#     counts = np.array(list(Counter(lst).values()))\n",
    "#     probs = counts / counts.sum()\n",
    "#     return -np.sum(probs * np.log2(probs))\n",
    "\n",
    "# def gini(array):\n",
    "#     array = [freq for freq in Counter(array).values()]\n",
    "#     array = np.sort(np.array(array))\n",
    "#     n = len(array)\n",
    "#     return (2 * np.sum((np.arange(1, n+1)) * array)) / (n * np.sum(array)) - (n + 1) / n\n",
    "\n",
    "# all_dics = [dic, dic2, dic3, dic4]\n",
    "# from scipy.stats import skew\n",
    "\n",
    "# for item in all_dics:\n",
    "#     print(skew(item[\"combined_seq_lens\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ebfcd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sglang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
