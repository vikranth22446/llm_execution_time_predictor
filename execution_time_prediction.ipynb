{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cd274492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_execution_time_predictor.train_utils import (\n",
    "    build_stage_features,\n",
    "    train_linear_predictor,\n",
    "    train_tree_predictor,\n",
    ")\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3cf6cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# List your files here\n",
    "# files = [\n",
    "#     \"arxiv_summarization_rps_3.jsonl\",\n",
    "#     \"decode_decode_profiling_tp0.jsonl\",\n",
    "#     \"prefill_prefill_profiling_tp0.jsonl\",\n",
    "#     \"prefill_profiling_chunked_cache_prefix_caching_prefill_cache_profiling_tp0.jsonl\",\n",
    "#     \"prefill_with_prefix_caching_prefill_cache_profiling_tp0.jsonl\",\n",
    "#     \"splitwise_code_rps_5.jsonl\",\n",
    "#     \"splitwise_code_rps_10.jsonl\"\n",
    "# ]\n",
    "model_name = \"Qwen_Qwen3_4B_TP_1\"\n",
    "files = os.listdir(\"profile_output/Qwen_Qwen3_4B_TP_1\")\n",
    "files_folder = [\n",
    "    os.path.join(\"profile_output/Qwen_Qwen3_4B_TP_1\", f) for f in files\n",
    "]\n",
    "dfs = [pd.read_json(f, lines=True) for f in files_folder]\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "combined_df.drop([\"throughput\", \"timestamp\", \"process_id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f12ee4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"combined_profile_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9bc13ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>total_token_length</th>\n",
       "      <th>skew</th>\n",
       "      <th>combined_seq_lens</th>\n",
       "      <th>cached_prefix_lens</th>\n",
       "      <th>new_extend_lens</th>\n",
       "      <th>total_extend_len</th>\n",
       "      <th>latency</th>\n",
       "      <th>forward_mode</th>\n",
       "      <th>cache_percent</th>\n",
       "      <th>chunked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012013</td>\n",
       "      <td>prefill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011156</td>\n",
       "      <td>prefill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010913</td>\n",
       "      <td>prefill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010928</td>\n",
       "      <td>prefill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>prefill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11839</th>\n",
       "      <td>1</td>\n",
       "      <td>1735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1735]</td>\n",
       "      <td>[1734]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>decode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11840</th>\n",
       "      <td>1</td>\n",
       "      <td>1736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1736]</td>\n",
       "      <td>[1735]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008114</td>\n",
       "      <td>decode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11841</th>\n",
       "      <td>1</td>\n",
       "      <td>1737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1737]</td>\n",
       "      <td>[1736]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008091</td>\n",
       "      <td>decode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11842</th>\n",
       "      <td>1</td>\n",
       "      <td>1738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1738]</td>\n",
       "      <td>[1737]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008102</td>\n",
       "      <td>decode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11843</th>\n",
       "      <td>1</td>\n",
       "      <td>1739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1739]</td>\n",
       "      <td>[1738]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008092</td>\n",
       "      <td>decode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11844 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       batch_size  total_token_length  skew combined_seq_lens  \\\n",
       "0               1                   1   0.0               [1]   \n",
       "1               1                   1   0.5               [1]   \n",
       "2               1                   1   1.0               [1]   \n",
       "3               1                   1   1.5               [1]   \n",
       "4               1                   2   0.0               [2]   \n",
       "...           ...                 ...   ...               ...   \n",
       "11839           1                1735   NaN            [1735]   \n",
       "11840           1                1736   NaN            [1736]   \n",
       "11841           1                1737   NaN            [1737]   \n",
       "11842           1                1738   NaN            [1738]   \n",
       "11843           1                1739   NaN            [1739]   \n",
       "\n",
       "      cached_prefix_lens new_extend_lens  total_extend_len   latency  \\\n",
       "0                    [0]             [1]               1.0  0.012013   \n",
       "1                    [0]             [1]               1.0  0.011156   \n",
       "2                    [0]             [1]               1.0  0.010913   \n",
       "3                    [0]             [1]               1.0  0.010928   \n",
       "4                    [0]             [2]               2.0  0.011433   \n",
       "...                  ...             ...               ...       ...   \n",
       "11839             [1734]             [1]               NaN  0.008086   \n",
       "11840             [1735]             [1]               NaN  0.008114   \n",
       "11841             [1736]             [1]               NaN  0.008091   \n",
       "11842             [1737]             [1]               NaN  0.008102   \n",
       "11843             [1738]             [1]               NaN  0.008092   \n",
       "\n",
       "      forward_mode  cache_percent chunked  \n",
       "0          prefill            NaN     NaN  \n",
       "1          prefill            NaN     NaN  \n",
       "2          prefill            NaN     NaN  \n",
       "3          prefill            NaN     NaN  \n",
       "4          prefill            NaN     NaN  \n",
       "...            ...            ...     ...  \n",
       "11839       decode            NaN     NaN  \n",
       "11840       decode            NaN     NaN  \n",
       "11841       decode            NaN     NaN  \n",
       "11842       decode            NaN     NaN  \n",
       "11843       decode            NaN     NaN  \n",
       "\n",
       "[11844 rows x 11 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435f394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "29cd56e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df.to_csv(\"combined_profile_results.csv\", index=False)\n",
    "import numpy as np\n",
    "combined_df[\"total_extend_len\"] = combined_df[\"total_extend_len\"].fillna(\n",
    "    combined_df[\"new_extend_lens\"].apply(sum)\n",
    ")\n",
    "\n",
    "combined_df[\"input_len\"] = combined_df[\"combined_seq_lens\"].apply(\n",
    "    lambda x: np.mean(x) if isinstance(x, list) else 0\n",
    ")\n",
    "prefill_df = combined_df[combined_df[\"forward_mode\"] == \"prefill\"]\n",
    "decode_df = combined_df[combined_df[\"forward_mode\"] == \"decode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ed5f57a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _safe_list(x):\n",
    "    \"\"\"Guard against NaN or scalar entries that sneak in.\"\"\"\n",
    "    return x if isinstance(x, (list, tuple, np.ndarray)) else [x]\n",
    "\n",
    "def build_stage_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Feature-engineer latency predictors for *both* prefill & decode rows.\n",
    "    The function assumes the raw frame still contains list-columns:\n",
    "      - combined_seq_lens\n",
    "      - cached_prefix_lens\n",
    "      - new_extend_lens\n",
    "    and extra scalar columns such as batch_size, latency, skew, cache_percent.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # 1.  Sequence-length distribution stats\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    df[\"len_max\"] = df[\"combined_seq_lens\"].apply(lambda x: np.max(_safe_list(x)))\n",
    "    df[\"len_min\"] = df[\"combined_seq_lens\"].apply(lambda x: np.min(_safe_list(x)))\n",
    "    df[\"len_std\"] = df[\"combined_seq_lens\"].apply(lambda x: np.std(_safe_list(x)))\n",
    "    df[\"len_p90\"] = df[\"combined_seq_lens\"].apply(\n",
    "        lambda x: np.percentile(_safe_list(x), 90)\n",
    "    )\n",
    "    df[\"len_p95\"] = df[\"combined_seq_lens\"].apply(\n",
    "        lambda x: np.percentile(_safe_list(x), 95)\n",
    "    )\n",
    "\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # 2.  Cached-prefix stats\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    df[\"cached_sum\"] = df[\"cached_prefix_lens\"].apply(\n",
    "        lambda x: np.sum(_safe_list(x))\n",
    "    )\n",
    "    df[\"cached_max\"] = df[\"cached_prefix_lens\"].apply(\n",
    "        lambda x: np.max(_safe_list(x))\n",
    "    )\n",
    "    df[\"cached_ratio\"] = df[\"cached_sum\"] / df[\"total_token_length\"].clip(lower=1)\n",
    "\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # 3.  Extension-stats (per call)\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    df[\"extend_sum\"] = df[\"new_extend_lens\"].apply(lambda x: np.sum(_safe_list(x)))\n",
    "    df[\"extend_max\"] = df[\"new_extend_lens\"].apply(lambda x: np.max(_safe_list(x)))\n",
    "    df[\"extend_mean\"] = df[\"new_extend_lens\"].apply(lambda x: np.mean(_safe_list(x)))\n",
    "    df[\"extend_std\"] = df[\"new_extend_lens\"].apply(lambda x: np.std(_safe_list(x)))\n",
    "    df[\"extend_p90\"] = df[\"new_extend_lens\"].apply(\n",
    "        lambda x: np.percentile(_safe_list(x), 90)\n",
    "    )\n",
    "\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # 4.  Skew / imbalance and memory-pressure proxies\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    df[\"imbalance\"] = df[\"len_max\"] / df[\"len_min\"].replace(0, np.nan)\n",
    "    df[\"cache_percent\"] = df.get(\"cache_percent\", np.nan)  # may already exist\n",
    "\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # 5.  Stage flag\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    df[\"is_prefill\"] = (df[\"forward_mode\"] == \"prefill\").astype(int)\n",
    "\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # 6.  “Classic” cost proxies (now using len_max instead of avg)\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # ATTENTION-FLOPs proxy: O(batch * len_max²) for prefill, O(batch * len_max) for decode\n",
    "    df[\"prod_ext_ctx\"] = np.where(\n",
    "        df[\"is_prefill\"] == 1,\n",
    "        df[\"batch_size\"] * (df[\"len_max\"] ** 2),\n",
    "        df[\"batch_size\"] * df[\"len_max\"],\n",
    "    )\n",
    "\n",
    "    # Tokens newly processed this step\n",
    "    df[\"num_new_tokens\"] = np.where(\n",
    "        df[\"is_prefill\"] == 1,\n",
    "        df[\"extend_sum\"],       # sum of prompt tokens\n",
    "        df[\"batch_size\"],       # one per sequence in decode\n",
    "    )\n",
    "\n",
    "    # Total context tokens “live” during this step\n",
    "    df[\"num_context_tokens\"] = df[\"batch_size\"] * df[\"len_max\"]\n",
    "\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # 7.  Target\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    df[\"time\"] = df[\"latency\"]\n",
    "\n",
    "    # ------- EXTRA SEQ / EXTENSION STATS -------\n",
    "    df[\"len_mean\"]   = df[\"combined_seq_lens\"].apply(lambda x: np.mean(_lst(x)))\n",
    "    df[\"len_median\"] = df[\"combined_seq_lens\"].apply(lambda x: np.median(_lst(x)))\n",
    "    df[\"len_range\"]  = df[\"len_max\"] - df[\"len_min\"]\n",
    "    df[\"len_p99\"]    = df[\"combined_seq_lens\"].apply(lambda x: np.percentile(_lst(x), 99))\n",
    "    df[\"len_cv\"]     = df[\"len_std\"] / df[\"len_mean\"].clip(lower=1)\n",
    "\n",
    "    df[\"extend_min\"]   = df[\"new_extend_lens\"].apply(lambda x: np.min(_lst(x)))\n",
    "    df[\"extend_median\"]= df[\"new_extend_lens\"].apply(lambda x: np.median(_lst(x)))\n",
    "    df[\"extend_p99\"]   = df[\"new_extend_lens\"].apply(lambda x: np.percentile(_lst(x), 99))\n",
    "    df[\"extend_cv\"]    = df[\"extend_std\"] / df[\"extend_mean\"].clip(lower=1)\n",
    "\n",
    "    # ------- RATIOS & INTERACTIONS -------\n",
    "    df[\"prompt_ratio\"]     = df[\"extend_sum\"] / df[\"total_token_length\"].clip(lower=1)\n",
    "    df[\"cached_peak_ratio\"]= df[\"cached_max\"] / df[\"len_max\"].clip(lower=1)\n",
    "    df[\"B_len_mean\"]       = df[\"batch_size\"] * df[\"len_mean\"]\n",
    "    df[\"B_len_max_sq\"]     = df[\"batch_size\"] * (df[\"len_max\"] ** 2)\n",
    "    df[\"cache_len_prod\"]   = df[\"cache_percent\"] * df[\"len_max\"]\n",
    "\n",
    "    # ------- LOG-SPACE -------\n",
    "    for col in [\"len_max\", \"prod_ext_ctx\", \"num_context_tokens\"]:\n",
    "        df[f\"log_{col}\"] = np.log1p(df[col])\n",
    "\n",
    "\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    # 8.  Select final columns\n",
    "    # ────────────────────────────────────────────────────────\n",
    "    feature_cols = [\n",
    "        # token & attention proxies\n",
    "        \"num_new_tokens\", \"prod_ext_ctx\", \"num_context_tokens\",\n",
    "        # sequence-distribution\n",
    "        \"len_max\", \"len_min\", \"len_std\", \"len_p90\", \"len_p95\",\n",
    "        # cache stats\n",
    "        \"cached_sum\", \"cached_max\", \"cached_ratio\",\n",
    "        # extension stats\n",
    "        \"extend_max\", \"extend_mean\", \"extend_std\", \"extend_p90\",\n",
    "        # imbalance / batch\n",
    "        \"batch_size\", \"imbalance\", \"skew\",\n",
    "        # memory pressure\n",
    "        \"cache_percent\",\n",
    "        # stage\n",
    "        \"is_prefill\",\n",
    "        # sequence shape\n",
    "        \"len_mean\",\"len_median\",\"len_range\",\"len_p99\",\"len_cv\",\n",
    "        # extension shape\n",
    "        \"extend_min\",\"extend_median\",\"extend_p99\",\"extend_cv\",\n",
    "        # ratios & interactions\n",
    "        \"prompt_ratio\",\"cached_peak_ratio\",\n",
    "        \"B_len_mean\",\"B_len_max_sq\",\"cache_len_prod\",\n",
    "        # log space\n",
    "        \"log_len_max\",\"log_prod_ext_ctx\",\"log_num_context_tokens\",\n",
    "    ]\n",
    "\n",
    "    # Keep any hardware-specific knobs if present (they’re cheap to one-hot later)\n",
    "#    hw_cols = [c for c in (\"gpu_name\", \"num_gpu\", \"dtype\", \"flash_attn_flag\") if c in df]\n",
    "    return df[feature_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e638d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import List, cast\n",
    "\n",
    "\n",
    "def preprocess_input_for_prediction(\n",
    "    batch_size, avg_context_len, gpu, mode=\"prefill\"\n",
    ") -> List[float]:\n",
    "    if mode == \"prefill\":\n",
    "        num_new_tokens = batch_size * avg_context_len\n",
    "        prod_ext_ctx = batch_size * (avg_context_len**2)\n",
    "        num_context_tokens = avg_context_len * batch_size\n",
    "        num_batch_size = batch_size\n",
    "    else:\n",
    "        num_new_tokens = batch_size\n",
    "        prod_ext_ctx = batch_size * avg_context_len\n",
    "        num_context_tokens = avg_context_len * batch_size\n",
    "        num_batch_size = batch_size\n",
    "    return [num_new_tokens, prod_ext_ctx, num_context_tokens, num_batch_size]\n",
    "\n",
    "\n",
    "def build_stage_features(df: pd.DataFrame, stage: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build input features for latency modeling based on the inference stage.\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A dataframe with engineered features:\n",
    "        - num_new_tokens: total tokens processed/generated (models token compute)\n",
    "        - prod_ext_ctx: proxy for attention cost (quadratic or linear depending on stage)\n",
    "        - num_context_tokens: total context tokens active (models memory + cache pressure)\n",
    "        - batch_size: degree of parallelism\n",
    "        - time: latency target to be predicted\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # TOOD: Currently I just use the average input length, but I should take in the actual batch composition seq lens, \n",
    "    if stage == \"prefill\":\n",
    "        df[\"num_new_tokens\"] = df[\"batch_size\"] * df[\"input_len\"]\n",
    "        df[\"prod_ext_ctx\"] = df[\"batch_size\"] * (df[\"input_len\"] ** 2)\n",
    "        df[\"num_context_tokens\"] = df[\"batch_size\"] * df[\"input_len\"]\n",
    "        df[\"time\"] = df[\"latency\"]\n",
    "\n",
    "    elif stage == \"decode\":\n",
    "        # One token is generated per request per step\n",
    "        # Each new token attends to all previous context (linear in output_len)\n",
    "        df[\"num_new_tokens\"] = df[\"batch_size\"]\n",
    "        df[\"prod_ext_ctx\"] = df[\"batch_size\"] * df[\"input_len\"]\n",
    "        df[\"num_context_tokens\"] = df[\"batch_size\"] * df[\"input_len\"]\n",
    "        df[\"time\"] = df[\"latency\"]\n",
    "    else:\n",
    "        raise ValueError(\"stage must be either 'prefill' or 'decode'\")\n",
    "\n",
    "    return df[\n",
    "        [\"num_new_tokens\", \"prod_ext_ctx\", \"num_context_tokens\", \"batch_size\", \"time\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "def train_linear_predictor(train_df: pd.DataFrame, name):\n",
    "    \"\"\"\n",
    "    Train a linear regression model to predict latency based on engineered features.\n",
    "    \"\"\"\n",
    "    X_train = train_df[\n",
    "        [\"num_new_tokens\", \"prod_ext_ctx\", \"num_context_tokens\", \"batch_size\"]\n",
    "    ].to_numpy(dtype=np.float32)\n",
    "    y_train = train_df[\"time\"].to_numpy(dtype=np.float32)\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_lr = lr_model.predict(X_train)\n",
    "\n",
    "    print(f\"Linear Regression: {name}\")\n",
    "    print(f\"Train RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_lr)) * 1000:.2f}ms\")\n",
    "    print(f\"Train MAE: {mean_absolute_error(y_train, y_pred_lr) * 1000:.2f}ms\")\n",
    "    print(f\"Train R2: {r2_score(y_train, y_pred_lr):.4f}\")\n",
    "    return lr_model\n",
    "\n",
    "\n",
    "def train_tree_predictor(train_df: pd.DataFrame, name):\n",
    "    \"\"\"\n",
    "    Train a decision tree model to predict latency based on engineered features.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract features and target\n",
    "    X_train = train_df[\n",
    "        [\"num_new_tokens\", \"prod_ext_ctx\", \"num_context_tokens\", \"batch_size\"]\n",
    "    ].to_numpy(dtype=np.float32)\n",
    "    y_train = train_df[\"time\"].to_numpy(dtype=np.float32)\n",
    "\n",
    "    # Fit Decision Tree Regressor\n",
    "    tree_model = RandomForestRegressor(\n",
    "        n_estimators=10, random_state=42, min_samples_leaf=2, max_depth=12\n",
    "    )\n",
    "    tree_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred_tree = tree_model.predict(X_train)\n",
    "\n",
    "    print(f\"Decision Tree: {name}\")\n",
    "    print(\n",
    "        f\"Train RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_tree)) * 1000:.2f}ms\"\n",
    "    )\n",
    "    print(f\"Train MAE: {mean_absolute_error(y_train, y_pred_tree) * 1000:.2f}ms\")\n",
    "    print(f\"Train R2: {r2_score(y_train, y_pred_tree):.4f}\")\n",
    "    return tree_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "18eccb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the 'batch_lens' column into a plain Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "254305b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_prefill = build_stage_features(prefill_df, stage=\"prefill\")\n",
    "train_df_decode = build_stage_features(decode_df, stage=\"decode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "62f93227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: prefill\n",
      "Train RMSE: 127.58ms\n",
      "Train MAE: 101.62ms\n",
      "Train R2: 0.3447\n",
      "Linear Regression: decode\n",
      "Train RMSE: 2.33ms\n",
      "Train MAE: 1.27ms\n",
      "Train R2: 0.9716\n"
     ]
    }
   ],
   "source": [
    "lr_model_prefill = train_linear_predictor(train_df_prefill, \"prefill\")\n",
    "lr_model_decode = train_linear_predictor(train_df_decode, \"decode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "918dd7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: prefill\n",
      "Train RMSE: 56.07ms\n",
      "Train MAE: 25.04ms\n",
      "Train R2: 0.8734\n",
      "Decision Tree: decode\n",
      "Train RMSE: 1.23ms\n",
      "Train MAE: 0.12ms\n",
      "Train R2: 0.9921\n"
     ]
    }
   ],
   "source": [
    "tr_model_prefill = train_tree_predictor(train_df_prefill, \"prefill\")\n",
    "tr_model_decode = train_tree_predictor(train_df_decode, \"decode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "250eaf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[prefill] training rows = 5592 validation rows = 57\n",
      "[prefill] LGBM\n",
      "Train RMSE: 1.04 ms\n",
      "Train MAE : 0.60 ms\n",
      "Train R²  : 1.00\n",
      "Val   RMSE: 2.13 ms\n",
      "Val   MAE : 1.15 ms\n",
      "Val   R²  : 1.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "MAE",
         "type": "scatter",
         "x": {
          "bdata": "okW28/1UEUCmm8QgsCpMQHWTGARWHX9A3SQGgVUzmUAAAAAAAG+zQA==",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "J/mdwTtu6D9TT9ieUQfSP4Cv77+1NeU/ueWhr/2o9T/995Nqkf8HQA==",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "colorbar": {
          "len": 0.5,
          "title": {
           "text": "MAE (ms)"
          },
          "y": 0.75,
          "yanchor": "middle"
         },
         "type": "heatmap",
         "x": [
          "(-6.614, 476.875]",
          "(476.875, 952.75]",
          "(952.75, 1428.625]",
          "(1428.625, 1904.5]",
          "(1904.5, 2380.375]",
          "(2380.375, 2856.25]",
          "(2856.25, 3332.125]",
          "(3332.125, 3808.0]",
          "(3808.0, 4283.875]",
          "(4283.875, 4759.75]",
          "(4759.75, 5235.625]",
          "(7139.125, 7615.0]"
         ],
         "xaxis": "x2",
         "y": [
          "(1.746, 17.875]",
          "(17.875, 33.75]",
          "(33.75, 49.625]",
          "(49.625, 65.5]",
          "(65.5, 81.375]",
          "(81.375, 97.25]",
          "(113.125, 129.0]",
          "(240.125, 256.0]"
         ],
         "yaxis": "y2",
         "z": {
          "bdata": "Xk+I4/cS2D9gj1ZR5SvyPwC0w7NNY90/aFu5TnvJAkAAAAAAAAD4fwAm56x63A5AgMotHaOCBkAAAAAAAAD4fyuLEaPTAQFAAAAAAAAA+H9A0l5ijBkDQLAThuvOCBlAMTdJunYJ9T8AAAAAAAD4fwDC/Y29LeQ/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/EHHsqEEE0D+A9RACOj4AQAAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H+AN+LB5P3/PwAAAAAAAPh/AEh4RcHWpj8AAAAAAAD4fwAAAAAAAPh/AHrSNV9npD8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AxNbmZWbbPwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/+MECDLg+5T8AAAAAAAD4fwAAAAAAAPh/gLCDhMyJ5D8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/kCN0IG4/0D8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/Ltl3BKjj2D8A/ArMgDXcPwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/kKSgJqI5/D8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/",
          "dtype": "f8",
          "shape": "8, 12"
         }
        },
        {
         "mode": "markers+lines",
         "name": "Normalized MAE by Avg Seq Len",
         "type": "scatter",
         "x": {
          "bdata": "okW28/1UEUCmm8QgsCpMQHWTGARWHX9A3SQGgVUzmUAAAAAAAG+zQA==",
          "dtype": "f8"
         },
         "xaxis": "x3",
         "y": {
          "bdata": "w0ZF/1sbGkBnAzDp/1IDQOdJ5h0tIAdArOIIHgtb+z/mx0XLwRLrPw==",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "cells": {
          "values": [
           [
            "RMSE",
            "MAE",
            "R²"
           ],
           [
            "1.04",
            "0.60",
            "1.00"
           ],
           [
            "2.13",
            "1.15",
            "1.00"
           ]
          ]
         },
         "domain": {
          "x": [
           0.6499999999999999,
           0.9999999999999999
          ],
          "y": [
           0,
           0.25
          ]
         },
         "header": {
          "values": [
           "Metric",
           "Train",
           "Validation"
          ]
         },
         "type": "table"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "MAE vs. Sequence Length",
          "x": 0.175,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "MAE Heatmap",
          "x": 0.825,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Normalized MAE vs. SeqLenMetrics",
          "x": 0.175,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.25,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 600,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 80
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "prefill lgm Qwen_Qwen3_4B_TP_1 Simulation Accuracy"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.35
         ],
         "title": {
          "text": "Seq Length"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.6499999999999999,
          0.9999999999999999
         ],
         "tickangle": -45,
         "title": {
          "text": "Seq Length"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.35
         ],
         "title": {
          "text": "Seq Length"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.75,
          1
         ],
         "title": {
          "text": "MAE (ms)"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.75,
          1
         ],
         "title": {
          "text": "Batch Size"
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.25
         ],
         "title": {
          "text": "Error (%)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[decode] training rows = 6133 validation rows = 62\n",
      "[decode] LGBM\n",
      "Train RMSE: 0.09 ms\n",
      "Train MAE : 0.05 ms\n",
      "Train R²  : 1.00\n",
      "Val   RMSE: 0.11 ms\n",
      "Val   MAE : 0.05 ms\n",
      "Val   R²  : 1.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "MAE",
         "type": "scatter",
         "x": {
          "bdata": "i2zn+6nXlEAAAAAAgBemQG4Sg8CqSKhAku18P1VDqkDJdr6fKl6yQAAAAACAS7pA",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "BpMbKNAIvT8zj83IqTyNP2YA4w2cQ5k/mpAQArU/lj+AZohYIbKnP7px3r6tR64/",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "colorbar": {
          "len": 0.5,
          "title": {
           "text": "MAE (ms)"
          },
          "y": 0.75,
          "yanchor": "middle"
         },
         "type": "heatmap",
         "x": [
          "(-6.553, 473.062]",
          "(1417.188, 1889.25]",
          "(2361.312, 2833.375]",
          "(2833.375, 3305.438]",
          "(3305.438, 3777.5]",
          "(3777.5, 4249.562]",
          "(5665.75, 6137.812]",
          "(6137.812, 6609.875]",
          "(7081.938, 7554.0]"
         ],
         "xaxis": "x2",
         "y": [
          "(0.772, 15.25]",
          "(29.5, 43.75]",
          "(43.75, 58.0]",
          "(58.0, 72.25]",
          "(86.5, 100.75]",
          "(115.0, 129.25]",
          "(214.75, 229.0]"
         ],
         "yaxis": "y2",
         "z": {
          "bdata": "NRt7n/lewD/gO4igC5nTPwBNlJLD6oc/jsAd4WcOmT/pquTJ7caHPwBgCFQ6Kno/AM9juxV6kT8AQ0MRy76UPwAAAAAAAPh/APs1uZ9Dsj8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwDkaW1VFag/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwDvDcY0SsA/AAAAAAAA+H8AAAAAAAD4fwDylw03XK4/gA3+BbOzsj8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4f4BiWDp9E9A/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AFGMEfHKsT8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAjIFkX+do/",
          "dtype": "f8",
          "shape": "7, 9"
         }
        },
        {
         "mode": "markers+lines",
         "name": "Normalized MAE by Avg Seq Len",
         "type": "scatter",
         "x": {
          "bdata": "i2zn+6nXlEAAAAAAgBemQG4Sg8CqSKhAku18P1VDqkDJdr6fKl6yQAAAAACAS7pA",
          "dtype": "f8"
         },
         "xaxis": "x3",
         "y": {
          "bdata": "5UrzdkpX7z/dlIiTQo+/P5mQKN1oRcs/mwZDgy8EyD+GwMk0CZTZP6tD2m++V+A/",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "cells": {
          "values": [
           [
            "RMSE",
            "MAE",
            "R²"
           ],
           [
            "0.09",
            "0.05",
            "1.00"
           ],
           [
            "0.11",
            "0.05",
            "1.00"
           ]
          ]
         },
         "domain": {
          "x": [
           0.6499999999999999,
           0.9999999999999999
          ],
          "y": [
           0,
           0.25
          ]
         },
         "header": {
          "values": [
           "Metric",
           "Train",
           "Validation"
          ]
         },
         "type": "table"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "MAE vs. Sequence Length",
          "x": 0.175,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "MAE Heatmap",
          "x": 0.825,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Normalized MAE vs. SeqLenMetrics",
          "x": 0.175,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.25,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 600,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 80
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "decode lgm Qwen_Qwen3_4B_TP_1 Simulation Accuracy"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.35
         ],
         "title": {
          "text": "Seq Length"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.6499999999999999,
          0.9999999999999999
         ],
         "tickangle": -45,
         "title": {
          "text": "Seq Length"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.35
         ],
         "title": {
          "text": "Seq Length"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.75,
          1
         ],
         "title": {
          "text": "MAE (ms)"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.75,
          1
         ],
         "title": {
          "text": "Batch Size"
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.25
         ],
         "title": {
          "text": "Error (%)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from llm_execution_time_predictor.train_utils import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1.  Stage-aware feature builder\n",
    "# ---------------------------------------------------------------------\n",
    "def build_stage_features(df: pd.DataFrame, *, stage: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create latency-prediction features for *one* stage (“prefill” or “decode”).\n",
    "    The function expects df to contain list-typed columns:\n",
    "      combined_seq_lens, cached_prefix_lens, new_extend_lens\n",
    "    plus scalar columns batch_size, latency, total_token_length, cache_percent.\n",
    "    \"\"\"\n",
    "    if stage not in (\"prefill\", \"decode\"):\n",
    "        raise ValueError(\"stage must be 'prefill' or 'decode'\")\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # ───── helper to coerce NaN / scalars into a 1-element list ─────\n",
    "    _lst = lambda x: x if isinstance(x, (list, tuple, np.ndarray)) else [x]\n",
    "\n",
    "    df[\"len_max\"] = df[\"combined_seq_lens\"].apply(lambda x: np.max(_lst(x)))\n",
    "    df[\"len_min\"] = df[\"combined_seq_lens\"].apply(lambda x: np.min(_lst(x)))\n",
    "    df[\"len_std\"] = df[\"combined_seq_lens\"].apply(lambda x: np.std(_lst(x)))\n",
    "    df[\"len_p90\"] = df[\"combined_seq_lens\"].apply(lambda x: np.percentile(_lst(x), 90))\n",
    "    df[\"len_p95\"] = df[\"combined_seq_lens\"].apply(lambda x: np.percentile(_lst(x), 95))\n",
    "\n",
    "    df[\"cached_sum\"] = df[\"cached_prefix_lens\"].apply(lambda x: np.sum(_lst(x)))\n",
    "    df[\"cached_max\"] = df[\"cached_prefix_lens\"].apply(lambda x: np.max(_lst(x)))\n",
    "    df[\"cached_ratio\"] = df[\"cached_sum\"] / df[\"total_token_length\"].clip(lower=1)\n",
    "\n",
    "    df[\"extend_sum\"]  = df[\"new_extend_lens\"].apply(lambda x: np.sum(_lst(x)))\n",
    "    df[\"extend_max\"]  = df[\"new_extend_lens\"].apply(lambda x: np.max(_lst(x)))\n",
    "    df[\"extend_mean\"] = df[\"new_extend_lens\"].apply(lambda x: np.mean(_lst(x)))\n",
    "    df[\"extend_std\"]  = df[\"new_extend_lens\"].apply(lambda x: np.std(_lst(x)))\n",
    "    df[\"extend_p90\"]  = df[\"new_extend_lens\"].apply(lambda x: np.percentile(_lst(x), 90))\n",
    "\n",
    "    df[\"imbalance\"]      = df[\"len_max\"] / df[\"len_min\"].replace(0, np.nan)\n",
    "    df[\"cache_percent\"]  = df.get(\"cache_percent\", np.nan)\n",
    "    if stage == \"prefill\":\n",
    "        df[\"num_new_tokens\"]    = df[\"extend_sum\"]                         # prompt tokens\n",
    "        df[\"prod_ext_ctx\"]      = df[\"batch_size\"] * (df[\"len_max\"] ** 2)  # O(B·L²)\n",
    "    else: \n",
    "        df[\"num_new_tokens\"]    = df[\"batch_size\"]                         # one per sequence\n",
    "        df[\"prod_ext_ctx\"]      = df[\"batch_size\"] * df[\"len_max\"]         # O(B·L)\n",
    "\n",
    "    df[\"num_context_tokens\"] = df[\"batch_size\"] * df[\"len_max\"]\n",
    "    df[\"time\"] = df[\"latency\"]\n",
    "\n",
    "    df[\"len_mean\"]   = df[\"combined_seq_lens\"].apply(lambda x: np.mean(_lst(x)))\n",
    "    df[\"len_median\"] = df[\"combined_seq_lens\"].apply(lambda x: np.median(_lst(x)))\n",
    "    df[\"len_range\"]  = df[\"len_max\"] - df[\"len_min\"]\n",
    "    df[\"len_p99\"]    = df[\"combined_seq_lens\"].apply(lambda x: np.percentile(_lst(x), 99))\n",
    "    df[\"len_cv\"]     = df[\"len_std\"] / df[\"len_mean\"].clip(lower=1)\n",
    "\n",
    "    df[\"extend_min\"]   = df[\"new_extend_lens\"].apply(lambda x: np.min(_lst(x)))\n",
    "    df[\"extend_median\"]= df[\"new_extend_lens\"].apply(lambda x: np.median(_lst(x)))\n",
    "    df[\"extend_p99\"]   = df[\"new_extend_lens\"].apply(lambda x: np.percentile(_lst(x), 99))\n",
    "    df[\"extend_cv\"]    = df[\"extend_std\"] / df[\"extend_mean\"].clip(lower=1)\n",
    "\n",
    "    df[\"prompt_ratio\"]     = df[\"extend_sum\"] / df[\"total_token_length\"].clip(lower=1)\n",
    "    df[\"cached_peak_ratio\"]= df[\"cached_max\"] / df[\"len_max\"].clip(lower=1)\n",
    "    df[\"B_len_mean\"]       = df[\"batch_size\"] * df[\"len_mean\"]\n",
    "    df[\"B_len_max_sq\"]     = df[\"batch_size\"] * (df[\"len_max\"] ** 2)\n",
    "    df[\"cache_len_prod\"]   = df[\"cache_percent\"] * df[\"len_max\"]\n",
    "\n",
    "    for col in [\"len_max\", \"prod_ext_ctx\", \"num_context_tokens\"]:\n",
    "        df[f\"log_{col}\"] = np.log1p(df[col])\n",
    "\n",
    "    keep = [\n",
    "        \"num_new_tokens\", \"prod_ext_ctx\", \"num_context_tokens\",\n",
    "        \"len_max\", \"len_min\", \"len_std\", \"len_p90\", \"len_p95\",\n",
    "        \"cached_sum\", \"cached_max\", \"cached_ratio\",\n",
    "        \"extend_max\", \"extend_mean\", \"extend_std\", \"extend_p90\",\n",
    "        \"batch_size\", \"imbalance\", \"skew\",\n",
    "        \"cache_percent\",\n",
    "        \"len_mean\",\"len_median\",\"len_range\",\"len_p99\",\"len_cv\",\n",
    "        \"extend_min\",\"extend_median\",\"extend_p99\",\"extend_cv\",\n",
    "        \"prompt_ratio\",\"cached_peak_ratio\",\n",
    "        \"B_len_mean\",\"B_len_max_sq\",\"cache_len_prod\",\n",
    "        \"log_len_max\",\"log_prod_ext_ctx\",\"log_num_context_tokens\",\n",
    "        \"time\",\n",
    "    ]\n",
    "    # keep hardware knobs if present\n",
    "    hw_cols = [c for c in (\"gpu_name\", \"num_gpu\", \"dtype\", \"flash_attn_flag\") if c in df]\n",
    "    return df[keep + hw_cols]\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from typing import Dict\n",
    "\n",
    "def find_closest_bin(value, bins: Dict):\n",
    "    for key, bin_val in bins.items():\n",
    "        if value <= key:\n",
    "            return bin_val\n",
    "    return bins[max(bins.keys())] \n",
    "    \n",
    "def find_closest_bin_for_all_lens(values, bins: Dict[int, int]):\n",
    "    return [find_closest_bin(v, bins) for v in values]\n",
    "\n",
    "def train_tree_predictor(train_df: pd.DataFrame, stage: str, model_type=\"lgm\", train_split_eval=True, model_name=\"Qwen3\", latency_normalization_dict=None) -> object:\n",
    "    \"\"\"\n",
    "    Dummy LightGBM regressor; swap this out with your real trainer.\n",
    "    \"\"\"\n",
    "    import lightgbm as lgb\n",
    "    X = train_df.drop(columns=[\"time\"])\n",
    "    y = train_df[\"time\"]\n",
    "\n",
    "    if model_type == \"lgm\":\n",
    "        model = lgb.LGBMRegressor(min_data_in_leaf=1, verbose=-1)\n",
    "    elif model_type == \"xgboost\":\n",
    "        model = xgb.XGBRegressor(\n",
    "            n_estimators=100, random_state=42, min_child_weight=1, max_depth=12\n",
    "        )\n",
    "    else:\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=10, random_state=42, min_samples_leaf=2, max_depth=12\n",
    "        ) \n",
    "    if train_split_eval:\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.01, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        print(f\"[{stage}] training rows =\", len(X_train), \"validation rows =\", len(X_val))\n",
    "\n",
    "        train_pred = model.predict(X_train)\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, train_pred)) * 1000\n",
    "        train_mae = mean_absolute_error(y_train, train_pred) * 1000\n",
    "        train_r2 = r2_score(y_train, train_pred)\n",
    "        \n",
    "        val_pred = model.predict(X_val)\n",
    "        val_rmse = np.sqrt(mean_squared_error(y_val, val_pred)) * 1000\n",
    "        val_mae = mean_absolute_error(y_val, val_pred) * 1000\n",
    "        val_r2 = r2_score(y_val, val_pred)\n",
    "        \n",
    "        print(f\"[{stage}] LGBM\")\n",
    "        print(f\"Train RMSE: {train_rmse:.2f} ms\")\n",
    "        print(f\"Train MAE : {train_mae:.2f} ms\")\n",
    "        print(f\"Train R²  : {train_r2:.2f}\")\n",
    "        print(f\"Val   RMSE: {val_rmse:.2f} ms\")\n",
    "        print(f\"Val   MAE : {val_mae:.2f} ms\")\n",
    "        print(f\"Val   R²  : {val_r2:.2f}\")\n",
    "\n",
    "        df_eval = pd.DataFrame({\n",
    "            'true': y_val * 1000,\n",
    "            'pred': val_pred * 1000,\n",
    "            'len_max': X_val['len_max'],\n",
    "            'batch_size': X_val['batch_size'],\n",
    "        })\n",
    "        df_eval['error_ms'] = (df_eval['true'] - df_eval['pred']).abs()\n",
    "        df_eval['len_bin'] = pd.qcut(df_eval['len_max'], q=6, duplicates='drop')\n",
    "        mae_by_len = df_eval.groupby('len_bin', observed=False)['error_ms'].mean().reset_index()\n",
    "        mae_by_len['len_center'] = mae_by_len['len_bin'].apply(lambda x: (x.left + x.right) / 2)\n",
    "        mae_by_len['len_bin_str'] = mae_by_len['len_bin'].astype(str)\n",
    "\n",
    "        df_eval['bs_bin'] = pd.cut(df_eval['batch_size'], bins=16)\n",
    "        df_eval['len_bin2'] = pd.cut(df_eval['len_max'], bins=16)\n",
    "        df_eval['bs_bin_str'] = pd.Categorical(df_eval['bs_bin'].astype(str), \n",
    "                                            categories=[str(cat) for cat in df_eval['bs_bin'].cat.categories],\n",
    "                                            ordered=True)\n",
    "\n",
    "        df_eval['len_bin2_str'] = pd.Categorical(df_eval['len_bin2'].astype(str), \n",
    "                                                categories=[str(cat) for cat in df_eval['len_bin2'].cat.categories],\n",
    "                                                ordered=True)\n",
    "        mae_by_len['error_ms_percent'] = [(mae_by_len.iloc[i]['error_ms'] / find_closest_bin(mae_by_len.iloc[i]['len_center'], latency_normalization_dict)) * 100 for i in range(len(mae_by_len))]\n",
    "\n",
    "        pivot = df_eval.pivot_table(\n",
    "            index='bs_bin_str',\n",
    "            columns='len_bin2_str',\n",
    "            values='error_ms',\n",
    "            aggfunc='mean',\n",
    "            observed=False\n",
    "        )\n",
    "\n",
    "        # ---- Create Subplots ----\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            specs=[\n",
    "                [{\"type\": \"xy\"},     {\"type\": \"xy\"}],\n",
    "                [{\"type\": \"xy\"},     {\"type\": \"domain\"}]\n",
    "            ],\n",
    "            subplot_titles=(\n",
    "                \"MAE vs. Sequence Length\",\n",
    "                \"MAE Heatmap\",\n",
    "                \"Normalized MAE vs. SeqLen\"\n",
    "                \"Metrics\"\n",
    "            ),\n",
    "            horizontal_spacing=0.3,\n",
    "            vertical_spacing=0.5\n",
    "        )\n",
    "\n",
    "        # 1) MAE vs. Sequence Length\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=mae_by_len['len_center'],\n",
    "                y=mae_by_len['error_ms'],\n",
    "                mode='markers+lines',\n",
    "                name='MAE'\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        fig.update_xaxes(title_text=\"Seq Length\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"MAE (ms)\", row=1, col=1)\n",
    "\n",
    "        # 2) Heatmap\n",
    "        fig.add_trace(\n",
    "            go.Heatmap(\n",
    "                z=pivot.values,\n",
    "                x=pivot.columns,\n",
    "                y=pivot.index,\n",
    "                colorbar=dict(\n",
    "                    title=\"MAE (ms)\",\n",
    "                    len=0.5,      # half the height of the subplot\n",
    "                    y=0.75,       # 75% up the entire figure\n",
    "                    yanchor=\"middle\"\n",
    "                )\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        fig.update_xaxes(title_text=\"Seq Length\", row=1, col=2, tickangle=-45)\n",
    "        fig.update_yaxes(title_text=\"Batch Size\", row=1, col=2)\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=mae_by_len['len_center'],\n",
    "                y=mae_by_len['error_ms_percent'],\n",
    "                mode='markers+lines',\n",
    "                name='Normalized MAE by Avg Seq Len'\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        fig.update_xaxes(title_text=\"Seq Length\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Error (%)\", row=2, col=1)\n",
    "\n",
    "        # 4) Metrics box (using a basic table for clarity)\n",
    "        fig.add_trace(\n",
    "            go.Table(\n",
    "                header=dict(values=[\"Metric\", \"Train\", \"Validation\"]),\n",
    "                cells=dict(values=[\n",
    "                    [\"RMSE\", \"MAE\", \"R²\"],\n",
    "                    [f\"{train_rmse:.2f}\", f\"{train_mae:.2f}\", f\"{train_r2:.2f}\"],\n",
    "                    [f\"{val_rmse:.2f}\",  f\"{val_mae:.2f}\",  f\"{val_r2:.2f}\"]\n",
    "                ])\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "\n",
    "        # final layout tweaks\n",
    "        fig.update_layout(\n",
    "            height=600,\n",
    "            width=1000,\n",
    "            title_text=f\"{stage} {model_type} {model_name} Simulation Accuracy\",\n",
    "            showlegend=False,\n",
    "            margin=dict(l=50, r=50, t=80, b=50)\n",
    "        )\n",
    "\n",
    "        fig.show() \n",
    "    else:\n",
    "        model.fit(X, y)\n",
    "        print(f\"[{stage}] training rows =\", len(train_df))\n",
    "        \n",
    "        y_pred = model.predict(X)\n",
    "        rmse = np.sqrt(mean_squared_error(y, y_pred)) * 1000  # → milliseconds\n",
    "        mae  = mean_absolute_error(y, y_pred) * 1000          # → milliseconds\n",
    "        r2   = r2_score(y, y_pred)\n",
    "\n",
    "        print(f\"[{stage}] RandomForest\")\n",
    "        print(f\"  Train RMSE: {rmse:.2f} ms\")\n",
    "        print(f\"  Train MAE : {mae:.2f} ms\")\n",
    "        print(f\"  Train R²  : {r2:.4f}\")\n",
    "    return model\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3.  End-to-end pipeline\n",
    "# ---------------------------------------------------------------------\n",
    "def train_latency_models(raw_df: pd.DataFrame, model_type=\"lgm\", train_split_eval=True, model_name=\"Qwen3\") -> Tuple:\n",
    "    \"\"\"\n",
    "    Preprocess → feature-engineer → train separate tree models for\n",
    "    prefill and decode.  Returns (prefill_model, decode_model).\n",
    "    \"\"\"\n",
    "    df = raw_df.copy()\n",
    "\n",
    "    # fill in total_extend_len if missing\n",
    "    df[\"total_extend_len\"] = df[\"total_extend_len\"].fillna(df[\"new_extend_lens\"].apply(sum))\n",
    "\n",
    "    # ensure list-typed columns stay lists when reading from CSV\n",
    "    list_cols = [\"combined_seq_lens\", \"cached_prefix_lens\", \"new_extend_lens\"]\n",
    "    for c in list_cols:\n",
    "        df[c] = df[c].apply(lambda v: v if isinstance(v, list) else eval(v))\n",
    "\n",
    "    # split by stage\n",
    "    prefill_df = df[df[\"forward_mode\"] == \"prefill\"]\n",
    "    decode_df  = df[df[\"forward_mode\"] == \"decode\"]\n",
    "\n",
    "    # build features\n",
    "    train_df_prefill = build_stage_features(prefill_df, stage=\"prefill\")\n",
    "    train_df_decode  = build_stage_features(decode_df,  stage=\"decode\")\n",
    "    forward_mode_to_filter = \"prefill\" \n",
    "    df_bs1_prefill = combined_df[(combined_df[\"batch_size\"] == 1) & (combined_df[\"skew\"] == 0) & (combined_df[\"forward_mode\"] == forward_mode_to_filter) & (combined_df[\"cache_percent\"] == 0.0)].filter(\n",
    "        [\"total_token_length\", \"latency\"]\n",
    "    ).set_index(\"total_token_length\") * 1000\n",
    "\n",
    "    prefill_latency_for_normalization = df_bs1_prefill.to_dict()['latency']\n",
    "\n",
    "\n",
    "    forward_mode_to_filter = \"decode\" \n",
    "    decode_bs_base = combined_df[(combined_df[\"skew\"] == 0) & (combined_df[\"forward_mode\"] == forward_mode_to_filter) & (combined_df[\"total_token_length\"] > 500)].groupby(\"batch_size\")[\"latency\"].mean() * 1000\n",
    "    decode_latency_for_normalization = decode_bs_base.to_dict()\n",
    "    \n",
    "    # train tree models\n",
    "    model_prefill = train_tree_predictor(train_df_prefill, \"prefill\", model_type=model_type, train_split_eval=train_split_eval, model_name=model_name, latency_normalization_dict=prefill_latency_for_normalization)\n",
    "    model_decode  = train_tree_predictor(train_df_decode,  \"decode\", model_type=model_type, train_split_eval=train_split_eval, model_name=model_name, latency_normalization_dict=decode_latency_for_normalization)\n",
    "    return model_prefill, model_decode\n",
    "\n",
    "\n",
    "model_prefill, model_decode = train_latency_models(combined_df, model_type=\"lgm\", train_split_eval=True, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "682a6203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 12.461132369935001, 2: 11.688116006553, 4: 11.735336855053001, 8: 11.697398498654001, 16: 11.520516127347001, 32: 11.301406659185002, 64: 11.661914177238001, 128: 11.711215600371002, 256: 16.398821026086, 512: 22.928835824131003, 1024: 40.913268923759006, 2048: 79.179731197655, 4096: 159.32115819305102, 8192: 354.56836968660303, 10240: 471.14018164575106, 13000: 639.3684521317481, 16384: 868.3463800698511}\n"
     ]
    }
   ],
   "source": [
    "forward_mode_to_filter = \"prefill\" \n",
    "df_bs1_prefill = combined_df[(combined_df[\"batch_size\"] == 1) & (combined_df[\"skew\"] == 0) & (combined_df[\"forward_mode\"] == forward_mode_to_filter) & (combined_df[\"cache_percent\"] == 0.0)].filter(\n",
    "    [\"total_token_length\", \"latency\"]\n",
    ").set_index(\"total_token_length\") * 1000\n",
    "\n",
    "prefill_latency_for_normalization = df_bs1_prefill.to_dict()['latency']\n",
    "print(prefill_latency_for_normalization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833ea220",
   "metadata": {},
   "source": [
    "<!-- [prefill] RandomForest\n",
    "Train RMSE: 0.08 ms\n",
    "Train MAE : 0.94 ms\n",
    "Train R²  : 1.00\n",
    "Val   RMSE: 0.04 ms\n",
    "Val   MAE : 0.74 ms\n",
    "Val   R²  : 1.00\n",
    "[decode] RandomForest\n",
    "Train RMSE: 0.03 ms\n",
    "Train MAE : 0.08 ms\n",
    "Train R²  : 0.99\n",
    "Val   RMSE: 0.06 ms\n",
    "Val   MAE : 0.27 ms\n",
    "Val   R²  : 0.95 -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0dc30ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [prefill] RandomForest\n",
    "# Train RMSE: 0.08 ms\n",
    "# Train MAE : 0.94 ms\n",
    "# Train R²  : 1.00\n",
    "# Val   RMSE: 0.04 ms\n",
    "# Val   MAE : 0.74 ms\n",
    "# Val   R²  : 1.00\n",
    "# [decode] RandomForest\n",
    "# Train RMSE: 0.03 ms\n",
    "# Train MAE : 0.08 ms\n",
    "# Train R²  : 0.99\n",
    "# Val   RMSE: 0.06 ms\n",
    "# Val   MAE : 0.27 ms\n",
    "# Val   R²  : 0.95\n",
    "\n",
    "# [prefill] LGBM\n",
    "# Train RMSE: 0.03 ms\n",
    "# Train MAE : 0.59 ms\n",
    "# Train R²  : 1.00\n",
    "# Val   RMSE: 0.03 ms\n",
    "# Val   MAE : 0.58 ms\n",
    "# Val   R²  : 1.00\n",
    "# [decode] LGBM\n",
    "# Train RMSE: 0.00 ms\n",
    "# Train MAE : 0.05 ms\n",
    "# Train R²  : 1.00\n",
    "# Val   RMSE: 0.00 ms\n",
    "# Val   MAE : 0.05 ms\n",
    "# Val   R²  : 1.00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f404d25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sglang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
